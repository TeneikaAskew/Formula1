{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TeneikaAskew/Formula1/blob/main/Random_Forest_and_Gradient_Boosting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTopwlutV0xW"
      },
      "source": [
        "# Feature Engineering\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kI0JB4teiPKO",
        "outputId": "0faa2e03-a220-4cac-a33d-9d24837164ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/Shared drives/Projects/Clicked/F1\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd '/content/drive/Shared drives/Projects/Clicked/F1'\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Suppress SettingWithCopyWarning\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "\n",
        "# Load your datasets (ensure the file paths are correct)\n",
        "drivers = pd.read_csv('drivers.csv')\n",
        "qualifying = pd.read_csv('qualifying.csv')\n",
        "races = pd.read_csv('races.csv')\n",
        "lap_times = pd.read_csv('lap_times.csv')\n",
        "pit_stop_times = pd.read_csv('pit_stops.csv')\n",
        "driver_standings = pd.read_csv('driver_standings.csv')\n",
        "results = pd.read_csv('results.csv')\n",
        "status = pd.read_csv('status.csv')\n",
        "constructor_results = pd.read_csv('constructor_results.csv')\n",
        "constructor_standings = pd.read_csv('constructor_standings.csv')\n",
        "\n",
        "# Identify drivers who finished the races\n",
        "finished_status_ids = status[status['status'].str.lower().isin(['finished', '1', 'active'])]['statusId'].unique()\n",
        "finished_results = results[results['statusId'].isin(finished_status_ids)]\n",
        "\n",
        "# Identify drivers who finished in the top 10 positions\n",
        "finished_results['top_10'] = finished_results['positionOrder'] <= 10\n",
        "\n",
        "# Merge races and results to get race year\n",
        "results = results.merge(races[['raceId', 'year']], on='raceId', how='left')\n",
        "\n",
        "# Calculate average position per season for each driver\n",
        "seasonal_performance = results.groupby(['driverId', 'year'])['positionOrder'].mean().reset_index()\n",
        "seasonal_performance.columns = ['driverId', 'year', 'avg_position_per_season']\n",
        "\n",
        "# Function to convert time\n",
        "def convert_time(time_str):\n",
        "    try:\n",
        "        if time_str == '\\\\N':\n",
        "            return 999 * 60 + 59.999\n",
        "        mins, secs = time_str.split(':')\n",
        "        return int(mins) * 60 + float(secs)\n",
        "    except:\n",
        "        return 999 * 60 + 59.999\n",
        "\n",
        "# Calculate average qualifying position for each driver\n",
        "qualifying['q1'] = qualifying['q1'].fillna('999:59.999').apply(convert_time)\n",
        "qualifying['q2'] = qualifying['q2'].fillna('999:59.999').apply(convert_time)\n",
        "qualifying['q3'] = qualifying['q3'].fillna('999:59.999').apply(convert_time)\n",
        "qualifying['qualifying_time'] = (\n",
        "    qualifying['q1'] + qualifying['q2'] + qualifying['q3']\n",
        ") / qualifying[['q1', 'q2', 'q3']].notna().sum(axis=1)\n",
        "avg_qualifying_position = qualifying.groupby('driverId')['position'].mean().reset_index()\n",
        "avg_qualifying_position.columns = ['driverId', 'avg_qualifying_position']\n",
        "\n",
        "# Calculate average team points\n",
        "avg_team_points = constructor_results.groupby('constructorId')['points'].mean().reset_index()\n",
        "avg_team_points.columns = ['constructorId', 'avg_team_points']\n",
        "\n",
        "# Merge all performance metrics into results dataframe\n",
        "results = results.merge(seasonal_performance, on=['driverId', 'year'], how='left')\n",
        "results = results.merge(avg_qualifying_position, on='driverId', how='left')\n",
        "results = results.merge(avg_team_points, on='constructorId', how='left')\n",
        "\n",
        "# Create interaction features\n",
        "results['qualifying_position_x_race_position'] = results['grid'] * results['positionOrder']\n",
        "results['qualifying_position_x_team_points'] = results['grid'] * results['avg_team_points']\n",
        "\n",
        "# Ensure the target variable exists\n",
        "results['top_10'] = results['positionOrder'] <= 10\n",
        "results['top_3'] = results['positionOrder'] <= 3\n",
        "\n",
        "# Additional feature engineering\n",
        "results['points_per_race'] = results['points'] / results['raceId'].map(results.groupby('raceId')['raceId'].count())\n",
        "results['constructor_points_per_race'] = results['constructorId'].map(constructor_results.groupby('constructorId')['points'].mean())\n",
        "results['driver_standing'] = results['driverId'].map(driver_standings.groupby('driverId')['points'].mean())\n",
        "results['avg_pit_stop_time'] = pit_stop_times.groupby('raceId')['milliseconds'].transform('mean') / 1000  # converting ms to seconds\n",
        "results['avg_lap_time'] = lap_times.groupby('raceId')['milliseconds'].transform('mean') / 1000  # converting ms to seconds\n",
        "\n",
        "# Calculate the number of top 10 and top 3 finishes for each driver\n",
        "top_10_counts = results.groupby('driverId')['top_10'].sum().reset_index()\n",
        "top_3_counts = results.groupby('driverId')['top_3'].sum().reset_index()\n",
        "\n",
        "top_10_counts.columns = ['driverId', 'top_10_count']\n",
        "top_3_counts.columns = ['driverId', 'top_3_count']\n",
        "\n",
        "results = results.merge(top_10_counts, on='driverId', how='left')\n",
        "results = results.merge(top_3_counts, on='driverId', how='left')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXWO737iiTk5"
      },
      "outputs": [],
      "source": [
        "# Prepare the data for training\n",
        "features = results[['grid', 'avg_position_per_season', 'avg_team_points', 'avg_qualifying_position',\n",
        "                    'qualifying_position_x_race_position', 'qualifying_position_x_team_points',\n",
        "                    'points_per_race', 'constructor_points_per_race', 'driver_standing',\n",
        "                    'top_10_count', 'top_3_count', 'avg_pit_stop_time', 'avg_lap_time']]\n",
        "target_top_10 = results['top_10']\n",
        "target_top_3 = results['top_3']\n",
        "\n",
        "# Drop any rows with missing values\n",
        "features = features.dropna()\n",
        "target_top_10 = target_top_10[features.index]\n",
        "target_top_3 = target_top_3[features.index]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbYqIrIEV7hu"
      },
      "source": [
        "## Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lw_dXksmV7X-"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and testing sets for both targets\n",
        "X_train, X_test, y_train_top_10, y_test_top_10 = train_test_split(features, target_top_10, test_size=0.2, random_state=42)\n",
        "X_train_top_3, X_test_top_3, y_train_top_3, y_test_top_3 = train_test_split(features, target_top_3, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply SMOTE to handle class imbalance for top 3 predictions\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_top_3_smote, y_train_top_3_smote = smote.fit_resample(X_train_top_3, y_train_top_3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMi6IVhcWA1j"
      },
      "source": [
        "## Random Forest, Gradient Boosting and Ensemble Model\n",
        "\n",
        "\n",
        "*   Hyperparameter Tuning\n",
        "*   Grid Search\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjqpRbNskaDU",
        "outputId": "ef00d016-1199-4583-9e6f-731643699b2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of CPUs: 2\n"
          ]
        }
      ],
      "source": [
        "# Initialize the models with hyperparameter tuning\n",
        "param_grid = {\n",
        "    'rf__n_estimators': [50, 100, 200], #can reduce parameters if taking too long\n",
        "    'gb__n_estimators': [50, 100, 200],\n",
        "    'gb__learning_rate': [0.01, 0.1, 0.2]\n",
        "}\n",
        "\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "gb_model = GradientBoostingClassifier(random_state=42)\n",
        "# gb_model = GradientBoostingClassifier(random_state=42, n_iter_no_change=5) Early Stopping for Gradient Boosting Use early stopping to reduce the number of iterations if no improvement is seen.\n",
        "\n",
        "# Ensemble model\n",
        "ensemble_model_top_10 = VotingClassifier(estimators=[('rf', rf_model), ('gb', gb_model)], voting='soft')\n",
        "ensemble_model_top_3 = VotingClassifier(estimators=[('rf', rf_model), ('gb', gb_model)], voting='soft')\n",
        "\n",
        "import multiprocessing\n",
        "n_cpus = multiprocessing.cpu_count()\n",
        "print(f\"Number of CPUs: {n_cpus}\")\n",
        "\n",
        "# Hyperparameter tuning using GridSearchCV\n",
        "grid_search_top_10 = GridSearchCV(estimator=ensemble_model_top_10, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=n_cpus)\n",
        "grid_search_top_3 = GridSearchCV(estimator=ensemble_model_top_3, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=n_cpus)\n",
        "grid_search_top_3_smote = GridSearchCV(estimator=ensemble_model_top_3, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=n_cpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZdS8YAiWWWQ"
      },
      "source": [
        "### Model Fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "id": "Tenf4lvCnRJR",
        "outputId": "c2738c32-ca9b-4237-8721-090dd087f642"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-16 {color: black;background-color: white;}#sk-container-id-16 pre{padding: 0;}#sk-container-id-16 div.sk-toggleable {background-color: white;}#sk-container-id-16 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-16 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-16 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-16 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-16 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-16 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-16 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-16 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-16 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-16 div.sk-item {position: relative;z-index: 1;}#sk-container-id-16 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-16 div.sk-item::before, #sk-container-id-16 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-16 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-16 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-16 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-16 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-16 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-16 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-16 div.sk-label-container {text-align: center;}#sk-container-id-16 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-16 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
              "             estimator=VotingClassifier(estimators=[(&#x27;rf&#x27;,\n",
              "                                                     RandomForestClassifier(random_state=42)),\n",
              "                                                    (&#x27;gb&#x27;,\n",
              "                                                     GradientBoostingClassifier(random_state=42))],\n",
              "                                        voting=&#x27;soft&#x27;),\n",
              "             n_jobs=2,\n",
              "             param_grid={&#x27;gb__learning_rate&#x27;: [0.01, 0.1, 0.2],\n",
              "                         &#x27;gb__n_estimators&#x27;: [50, 100, 200],\n",
              "                         &#x27;rf__n_estimators&#x27;: [50, 100, 200]},\n",
              "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-61\" type=\"checkbox\" ><label for=\"sk-estimator-id-61\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
              "             estimator=VotingClassifier(estimators=[(&#x27;rf&#x27;,\n",
              "                                                     RandomForestClassifier(random_state=42)),\n",
              "                                                    (&#x27;gb&#x27;,\n",
              "                                                     GradientBoostingClassifier(random_state=42))],\n",
              "                                        voting=&#x27;soft&#x27;),\n",
              "             n_jobs=2,\n",
              "             param_grid={&#x27;gb__learning_rate&#x27;: [0.01, 0.1, 0.2],\n",
              "                         &#x27;gb__n_estimators&#x27;: [50, 100, 200],\n",
              "                         &#x27;rf__n_estimators&#x27;: [50, 100, 200]},\n",
              "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-62\" type=\"checkbox\" ><label for=\"sk-estimator-id-62\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;rf&#x27;, RandomForestClassifier(random_state=42)),\n",
              "                             (&#x27;gb&#x27;,\n",
              "                              GradientBoostingClassifier(random_state=42))],\n",
              "                 voting=&#x27;soft&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-63\" type=\"checkbox\" ><label for=\"sk-estimator-id-63\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>gb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-64\" type=\"checkbox\" ><label for=\"sk-estimator-id-64\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "GridSearchCV(cv=5,\n",
              "             estimator=VotingClassifier(estimators=[('rf',\n",
              "                                                     RandomForestClassifier(random_state=42)),\n",
              "                                                    ('gb',\n",
              "                                                     GradientBoostingClassifier(random_state=42))],\n",
              "                                        voting='soft'),\n",
              "             n_jobs=2,\n",
              "             param_grid={'gb__learning_rate': [0.01, 0.1, 0.2],\n",
              "                         'gb__n_estimators': [50, 100, 200],\n",
              "                         'rf__n_estimators': [50, 100, 200]},\n",
              "             scoring='accuracy')"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Fit the models - top 10\n",
        "grid_search_top_10.fit(X_train, y_train_top_10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "id": "RMS5YPBQicv8",
        "outputId": "493c098f-899b-44b5-f812-8b784951203c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-17 {color: black;background-color: white;}#sk-container-id-17 pre{padding: 0;}#sk-container-id-17 div.sk-toggleable {background-color: white;}#sk-container-id-17 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-17 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-17 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-17 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-17 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-17 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-17 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-17 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-17 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-17 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-17 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-17 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-17 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-17 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-17 div.sk-item {position: relative;z-index: 1;}#sk-container-id-17 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-17 div.sk-item::before, #sk-container-id-17 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-17 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-17 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-17 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-17 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-17 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-17 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-17 div.sk-label-container {text-align: center;}#sk-container-id-17 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-17 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-17\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
              "             estimator=VotingClassifier(estimators=[(&#x27;rf&#x27;,\n",
              "                                                     RandomForestClassifier(random_state=42)),\n",
              "                                                    (&#x27;gb&#x27;,\n",
              "                                                     GradientBoostingClassifier(random_state=42))],\n",
              "                                        voting=&#x27;soft&#x27;),\n",
              "             n_jobs=2,\n",
              "             param_grid={&#x27;gb__learning_rate&#x27;: [0.01, 0.1, 0.2],\n",
              "                         &#x27;gb__n_estimators&#x27;: [50, 100, 200],\n",
              "                         &#x27;rf__n_estimators&#x27;: [50, 100, 200]},\n",
              "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-65\" type=\"checkbox\" ><label for=\"sk-estimator-id-65\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
              "             estimator=VotingClassifier(estimators=[(&#x27;rf&#x27;,\n",
              "                                                     RandomForestClassifier(random_state=42)),\n",
              "                                                    (&#x27;gb&#x27;,\n",
              "                                                     GradientBoostingClassifier(random_state=42))],\n",
              "                                        voting=&#x27;soft&#x27;),\n",
              "             n_jobs=2,\n",
              "             param_grid={&#x27;gb__learning_rate&#x27;: [0.01, 0.1, 0.2],\n",
              "                         &#x27;gb__n_estimators&#x27;: [50, 100, 200],\n",
              "                         &#x27;rf__n_estimators&#x27;: [50, 100, 200]},\n",
              "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-66\" type=\"checkbox\" ><label for=\"sk-estimator-id-66\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;rf&#x27;, RandomForestClassifier(random_state=42)),\n",
              "                             (&#x27;gb&#x27;,\n",
              "                              GradientBoostingClassifier(random_state=42))],\n",
              "                 voting=&#x27;soft&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-67\" type=\"checkbox\" ><label for=\"sk-estimator-id-67\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>gb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-68\" type=\"checkbox\" ><label for=\"sk-estimator-id-68\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "GridSearchCV(cv=5,\n",
              "             estimator=VotingClassifier(estimators=[('rf',\n",
              "                                                     RandomForestClassifier(random_state=42)),\n",
              "                                                    ('gb',\n",
              "                                                     GradientBoostingClassifier(random_state=42))],\n",
              "                                        voting='soft'),\n",
              "             n_jobs=2,\n",
              "             param_grid={'gb__learning_rate': [0.01, 0.1, 0.2],\n",
              "                         'gb__n_estimators': [50, 100, 200],\n",
              "                         'rf__n_estimators': [50, 100, 200]},\n",
              "             scoring='accuracy')"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Fit the models - top 3 without SMOTE\n",
        "grid_search_top_3.fit(X_train_top_3, y_train_top_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "id": "2F6DquIgnTmj",
        "outputId": "a1e34eb4-31c8-4130-cab2-d586bf8965d6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-20 {color: black;background-color: white;}#sk-container-id-20 pre{padding: 0;}#sk-container-id-20 div.sk-toggleable {background-color: white;}#sk-container-id-20 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-20 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-20 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-20 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-20 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-20 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-20 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-20 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-20 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-20 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-20 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-20 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-20 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-20 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-20 div.sk-item {position: relative;z-index: 1;}#sk-container-id-20 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-20 div.sk-item::before, #sk-container-id-20 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-20 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-20 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-20 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-20 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-20 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-20 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-20 div.sk-label-container {text-align: center;}#sk-container-id-20 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-20 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-20\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
              "             estimator=VotingClassifier(estimators=[(&#x27;rf&#x27;,\n",
              "                                                     RandomForestClassifier(random_state=42)),\n",
              "                                                    (&#x27;gb&#x27;,\n",
              "                                                     GradientBoostingClassifier(random_state=42))],\n",
              "                                        voting=&#x27;soft&#x27;),\n",
              "             n_jobs=2,\n",
              "             param_grid={&#x27;gb__learning_rate&#x27;: [0.01, 0.1, 0.2],\n",
              "                         &#x27;gb__n_estimators&#x27;: [50, 100, 200],\n",
              "                         &#x27;rf__n_estimators&#x27;: [50, 100, 200]},\n",
              "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-77\" type=\"checkbox\" ><label for=\"sk-estimator-id-77\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
              "             estimator=VotingClassifier(estimators=[(&#x27;rf&#x27;,\n",
              "                                                     RandomForestClassifier(random_state=42)),\n",
              "                                                    (&#x27;gb&#x27;,\n",
              "                                                     GradientBoostingClassifier(random_state=42))],\n",
              "                                        voting=&#x27;soft&#x27;),\n",
              "             n_jobs=2,\n",
              "             param_grid={&#x27;gb__learning_rate&#x27;: [0.01, 0.1, 0.2],\n",
              "                         &#x27;gb__n_estimators&#x27;: [50, 100, 200],\n",
              "                         &#x27;rf__n_estimators&#x27;: [50, 100, 200]},\n",
              "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-78\" type=\"checkbox\" ><label for=\"sk-estimator-id-78\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;rf&#x27;, RandomForestClassifier(random_state=42)),\n",
              "                             (&#x27;gb&#x27;,\n",
              "                              GradientBoostingClassifier(random_state=42))],\n",
              "                 voting=&#x27;soft&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-79\" type=\"checkbox\" ><label for=\"sk-estimator-id-79\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>gb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-80\" type=\"checkbox\" ><label for=\"sk-estimator-id-80\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "GridSearchCV(cv=5,\n",
              "             estimator=VotingClassifier(estimators=[('rf',\n",
              "                                                     RandomForestClassifier(random_state=42)),\n",
              "                                                    ('gb',\n",
              "                                                     GradientBoostingClassifier(random_state=42))],\n",
              "                                        voting='soft'),\n",
              "             n_jobs=2,\n",
              "             param_grid={'gb__learning_rate': [0.01, 0.1, 0.2],\n",
              "                         'gb__n_estimators': [50, 100, 200],\n",
              "                         'rf__n_estimators': [50, 100, 200]},\n",
              "             scoring='accuracy')"
            ]
          },
          "execution_count": 129,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# # Fit the models - top 3 with SMOTE\n",
        "grid_search_top_3_smote = GridSearchCV(estimator=ensemble_model_top_3, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=n_cpus) #use cpus that are available (2)\n",
        "#grid_search_top_3_smote = GridSearchCV(estimator=ensemble_model_top_3, param_grid=param_grid, cv=5, n_jobs=-1)  # Use all available cores\n",
        "grid_search_top_3_smote.fit(X_train_top_3_smote, y_train_top_3_smote)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1MizEzTY5Kmw",
        "outputId": "0f2384fa-95c6-4433-b98b-9ad2e6e22b16"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-21 {color: black;background-color: white;}#sk-container-id-21 pre{padding: 0;}#sk-container-id-21 div.sk-toggleable {background-color: white;}#sk-container-id-21 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-21 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-21 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-21 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-21 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-21 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-21 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-21 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-21 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-21 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-21 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-21 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-21 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-21 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-21 div.sk-item {position: relative;z-index: 1;}#sk-container-id-21 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-21 div.sk-item::before, #sk-container-id-21 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-21 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-21 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-21 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-21 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-21 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-21 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-21 div.sk-label-container {text-align: center;}#sk-container-id-21 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-21 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-21\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
              "             estimator=VotingClassifier(estimators=[(&#x27;rf&#x27;,\n",
              "                                                     RandomForestClassifier(random_state=42)),\n",
              "                                                    (&#x27;gb&#x27;,\n",
              "                                                     GradientBoostingClassifier(random_state=42))],\n",
              "                                        voting=&#x27;soft&#x27;),\n",
              "             n_jobs=-1,\n",
              "             param_grid={&#x27;gb__learning_rate&#x27;: [0.01, 0.1, 0.2],\n",
              "                         &#x27;gb__n_estimators&#x27;: [50, 100, 200],\n",
              "                         &#x27;rf__n_estimators&#x27;: [50, 100, 200]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-81\" type=\"checkbox\" ><label for=\"sk-estimator-id-81\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
              "             estimator=VotingClassifier(estimators=[(&#x27;rf&#x27;,\n",
              "                                                     RandomForestClassifier(random_state=42)),\n",
              "                                                    (&#x27;gb&#x27;,\n",
              "                                                     GradientBoostingClassifier(random_state=42))],\n",
              "                                        voting=&#x27;soft&#x27;),\n",
              "             n_jobs=-1,\n",
              "             param_grid={&#x27;gb__learning_rate&#x27;: [0.01, 0.1, 0.2],\n",
              "                         &#x27;gb__n_estimators&#x27;: [50, 100, 200],\n",
              "                         &#x27;rf__n_estimators&#x27;: [50, 100, 200]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-82\" type=\"checkbox\" ><label for=\"sk-estimator-id-82\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;rf&#x27;, RandomForestClassifier(random_state=42)),\n",
              "                             (&#x27;gb&#x27;,\n",
              "                              GradientBoostingClassifier(random_state=42))],\n",
              "                 voting=&#x27;soft&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-83\" type=\"checkbox\" ><label for=\"sk-estimator-id-83\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>gb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-84\" type=\"checkbox\" ><label for=\"sk-estimator-id-84\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "GridSearchCV(cv=5,\n",
              "             estimator=VotingClassifier(estimators=[('rf',\n",
              "                                                     RandomForestClassifier(random_state=42)),\n",
              "                                                    ('gb',\n",
              "                                                     GradientBoostingClassifier(random_state=42))],\n",
              "                                        voting='soft'),\n",
              "             n_jobs=-1,\n",
              "             param_grid={'gb__learning_rate': [0.01, 0.1, 0.2],\n",
              "                         'gb__n_estimators': [50, 100, 200],\n",
              "                         'rf__n_estimators': [50, 100, 200]})"
            ]
          },
          "execution_count": 130,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# # Fit the models - top 3 with SMOTE\n",
        "grid_search_top_3_smote = GridSearchCV(estimator=ensemble_model_top_3, param_grid=param_grid, cv=5, n_jobs=-1)  # Use all available cores\n",
        "grid_search_top_3_smote.fit(X_train_top_3_smote, y_train_top_3_smote)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GERoOsah5jku"
      },
      "outputs": [],
      "source": [
        "import concurrent.futures\n",
        "# Fit the models using concurrent.futures\n",
        "with concurrent.futures.ThreadPoolExecutor(max_workers=n_cpus) as executor:\n",
        "    future_top_10 = executor.submit(grid_search_top_10.fit, X_train, y_train_top_10)\n",
        "    future_top_3 = executor.submit(grid_search_top_3.fit, X_train_top_3, y_train_top_3)\n",
        "    future_top_3_smote = executor.submit(grid_search_top_3_smote.fit, X_train_top_3_smote, y_train_top_3_smote)\n",
        "\n",
        "    # Wait for all threads to complete\n",
        "    concurrent.futures.wait([future_top_10, future_top_3, future_top_3_smote])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQ8FBcPduTzC",
        "outputId": "7ac7a8a9-c896-45e8-9938-da9f7eb57361"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest Results:\n",
            "Accuracy: 0.9974921630094044\n",
            "Precision: 0.9905660377358491\n",
            "Recall: 0.9905660377358491\n",
            "F1 Score: 0.9905660377358491\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       1.00      1.00      1.00      1383\n",
            "        True       0.99      0.99      0.99       212\n",
            "\n",
            "    accuracy                           1.00      1595\n",
            "   macro avg       0.99      0.99      0.99      1595\n",
            "weighted avg       1.00      1.00      1.00      1595\n",
            "\n",
            "Gradient Boosting Results:\n",
            "Accuracy: 0.9987460815047022\n",
            "Precision: 0.9906542056074766\n",
            "Recall: 1.0\n",
            "F1 Score: 0.9953051643192489\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       1.00      1.00      1.00      1383\n",
            "        True       0.99      1.00      1.00       212\n",
            "\n",
            "    accuracy                           1.00      1595\n",
            "   macro avg       1.00      1.00      1.00      1595\n",
            "weighted avg       1.00      1.00      1.00      1595\n",
            "\n",
            "Cross-Validation Results for Random Forest: {'mean_fit_time': array([1.44609671, 3.26436315, 3.72790689, 0.69798231, 2.36944828,\n",
            "       2.97086015, 0.72064438, 2.00037327, 3.41437435]), 'std_fit_time': array([0.2695522 , 0.62231241, 1.08990713, 0.01278287, 0.15966663,\n",
            "       0.40917522, 0.00887866, 0.45085009, 1.00033719]), 'mean_score_time': array([0.04513359, 0.09983664, 0.07664561, 0.02520509, 0.07789645,\n",
            "       0.0683548 , 0.02190051, 0.06280093, 0.06760216]), 'std_score_time': array([0.00865019, 0.0351641 , 0.00900474, 0.00736698, 0.00732379,\n",
            "       0.00135224, 0.00048655, 0.01375948, 0.00761083]), 'param_max_depth': masked_array(data=[None, None, None, 10, 10, 10, 20, 20, 20],\n",
            "             mask=[False, False, False, False, False, False, False, False,\n",
            "                   False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'param_n_estimators': masked_array(data=[50, 100, 200, 50, 100, 200, 50, 100, 200],\n",
            "             mask=[False, False, False, False, False, False, False, False,\n",
            "                   False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'params': [{'max_depth': None, 'n_estimators': 50}, {'max_depth': None, 'n_estimators': 100}, {'max_depth': None, 'n_estimators': 200}, {'max_depth': 10, 'n_estimators': 50}, {'max_depth': 10, 'n_estimators': 100}, {'max_depth': 10, 'n_estimators': 200}, {'max_depth': 20, 'n_estimators': 50}, {'max_depth': 20, 'n_estimators': 100}, {'max_depth': 20, 'n_estimators': 200}], 'split0_test_score': array([0.9954894 , 0.99368516, 0.99458728, 0.99007668, 0.99007668,\n",
            "       0.99007668, 0.9954894 , 0.99368516, 0.99458728]), 'split1_test_score': array([0.99954894, 0.99954894, 0.99909788, 0.9977447 , 0.99729364,\n",
            "       0.9977447 , 0.99954894, 0.99954894, 0.99909788]), 'split2_test_score': array([0.99729364, 0.99639152, 0.99684258, 0.9954894 , 0.9954894 ,\n",
            "       0.99503834, 0.99729364, 0.99639152, 0.99684258]), 'split3_test_score': array([0.99503834, 0.99503834, 0.99458728, 0.99233198, 0.99188092,\n",
            "       0.99278304, 0.99503834, 0.99503834, 0.99458728]), 'split4_test_score': array([0.99819495, 0.99819495, 0.99909747, 0.9950361 , 0.99684116,\n",
            "       0.99729242, 0.99819495, 0.99819495, 0.99864621]), 'mean_test_score': array([0.99711305, 0.99657178, 0.9968425 , 0.99413577, 0.99431636,\n",
            "       0.99458704, 0.99711305, 0.99657178, 0.99675225]), 'std_test_score': array([0.00167794, 0.00210783, 0.00201711, 0.00266072, 0.00284679,\n",
            "       0.00286675, 0.00167794, 0.00210783, 0.00192205]), 'rank_test_score': array([1, 5, 3, 9, 8, 7, 1, 5, 4], dtype=int32)}\n",
            "Cross-Validation Results for Gradient Boosting: {'mean_fit_time': array([1.54696445, 4.11513634, 8.22725906, 2.18197122, 9.52353249,\n",
            "       8.05256996, 1.8527267 , 3.00592818, 6.75893993]), 'std_fit_time': array([0.17799914, 0.71759272, 1.74641812, 0.50861236, 1.807676  ,\n",
            "       2.13419794, 0.55042097, 0.22777701, 1.69955889]), 'mean_score_time': array([0.00997458, 0.01370482, 0.01714597, 0.01140995, 0.02997718,\n",
            "       0.01703105, 0.00758114, 0.01254358, 0.01443124]), 'std_score_time': array([0.0056148 , 0.00560258, 0.00576455, 0.00529799, 0.01335207,\n",
            "       0.00555759, 0.00032336, 0.00453546, 0.00104343]), 'param_learning_rate': masked_array(data=[0.01, 0.01, 0.01, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2],\n",
            "             mask=[False, False, False, False, False, False, False, False,\n",
            "                   False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'param_n_estimators': masked_array(data=[50, 100, 200, 50, 100, 200, 50, 100, 200],\n",
            "             mask=[False, False, False, False, False, False, False, False,\n",
            "                   False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'params': [{'learning_rate': 0.01, 'n_estimators': 50}, {'learning_rate': 0.01, 'n_estimators': 100}, {'learning_rate': 0.01, 'n_estimators': 200}, {'learning_rate': 0.1, 'n_estimators': 50}, {'learning_rate': 0.1, 'n_estimators': 100}, {'learning_rate': 0.1, 'n_estimators': 200}, {'learning_rate': 0.2, 'n_estimators': 50}, {'learning_rate': 0.2, 'n_estimators': 100}, {'learning_rate': 0.2, 'n_estimators': 200}], 'split0_test_score': array([0.98376184, 0.98376184, 0.98331078, 0.99007668, 0.99278304,\n",
            "       0.99729364, 0.9932341 , 0.9977447 , 0.99909788]), 'split1_test_score': array([0.9819576 , 0.98466396, 0.98737032, 0.99368516, 0.99864682,\n",
            "       1.        , 0.99729364, 0.99954894, 1.        ]), 'split2_test_score': array([0.98240866, 0.98376184, 0.98691926, 0.99368516, 0.99819576,\n",
            "       0.9977447 , 0.99729364, 0.9977447 , 0.99819576]), 'split3_test_score': array([0.97338746, 0.98376184, 0.98511502, 0.99052774, 0.99594046,\n",
            "       0.99864682, 0.99639152, 0.99909788, 0.99909788]), 'split4_test_score': array([0.98194946, 0.98240072, 0.98555957, 0.99277978, 0.99864621,\n",
            "       1.        , 0.99774368, 0.99864621, 1.        ]), 'mean_test_score': array([0.980693  , 0.98367004, 0.98565499, 0.9921509 , 0.99684246,\n",
            "       0.99873703, 0.99639132, 0.99855649, 0.9992783 ]), 'std_test_score': array([0.00371241, 0.00072448, 0.00143783, 0.0015518 , 0.00226421,\n",
            "       0.0011195 , 0.00163861, 0.00072168, 0.00067508]), 'rank_test_score': array([9, 8, 7, 6, 4, 2, 5, 3, 1], dtype=int32)}\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "# def perform_grid_search(model, param_grid, X_train, y_train, X_test, y_test, scoring='accuracy', n_jobs=-1, cv=5):\n",
        "#     grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=cv, scoring=scoring, n_jobs=n_jobs)\n",
        "#     grid_search.fit(X_train, y_train)\n",
        "#     best_model = grid_search.best_estimator_\n",
        "\n",
        "#     y_pred = best_model.predict(X_test)\n",
        "#     accuracy = accuracy_score(y_test, y_pred)\n",
        "#     precision = precision_score(y_test, y_pred)\n",
        "#     recall = recall_score(y_test, y_pred)\n",
        "#     f1 = f1_score(y_test, y_pred)\n",
        "#     class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "#     return {\n",
        "#         'best_model': best_model,\n",
        "#         'accuracy': accuracy,\n",
        "#         'precision': precision,\n",
        "#         'recall': recall,\n",
        "#         'f1': f1,\n",
        "#         'classification_report': class_report,\n",
        "#         'cv_results': grid_search.cv_results_\n",
        "#     }\n",
        "\n",
        "# import multiprocessing\n",
        "# from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
        "\n",
        "# # Define parameter grids\n",
        "# param_grid_rf = {\n",
        "#     'n_estimators': [50, 100, 200],\n",
        "#     'max_depth': [None, 10, 20],\n",
        "# }\n",
        "\n",
        "# param_grid_gb = {\n",
        "#     'n_estimators': [50, 100, 200],\n",
        "#     'learning_rate': [0.01, 0.1, 0.2]\n",
        "# }\n",
        "\n",
        "# # Define models\n",
        "# rf_model = RandomForestClassifier(random_state=42)\n",
        "# gb_model = GradientBoostingClassifier(random_state=42)\n",
        "\n",
        "# # Ensemble model\n",
        "# ensemble_model_top_3 = VotingClassifier(estimators=[('rf', rf_model), ('gb', gb_model)], voting='soft')\n",
        "\n",
        "# # Prepare data for SMOTE (this should be defined earlier in your script)\n",
        "# smote = SMOTE(random_state=42)\n",
        "# X_train_top_3_smote, y_train_top_3_smote = smote.fit_resample(X_train_top_3, y_train_top_3)\n",
        "\n",
        "# # Number of CPUs\n",
        "# n_cpus = multiprocessing.cpu_count()\n",
        "\n",
        "# # Run grid searches\n",
        "# results_rf = perform_grid_search(rf_model, param_grid_rf, X_train_top_3_smote, y_train_top_3_smote, X_test_top_3, y_test_top_3, n_jobs=n_cpus)\n",
        "# results_gb = perform_grid_search(gb_model, param_grid_gb, X_train_top_3_smote, y_train_top_3_smote, X_test_top_3, y_test_top_3, n_jobs=n_cpus)\n",
        "\n",
        "# # Print results for RandomForest\n",
        "# print('Random Forest Results:')\n",
        "# print(f'Accuracy: {results_rf[\"accuracy\"]}')\n",
        "# print(f'Precision: {results_rf[\"precision\"]}')\n",
        "# print(f'Recall: {results_rf[\"recall\"]}')\n",
        "# print(f'F1 Score: {results_rf[\"f1\"]}')\n",
        "# print('Classification Report:')\n",
        "# print(results_rf['classification_report'])\n",
        "\n",
        "# # Print results for GradientBoosting\n",
        "# print('Gradient Boosting Results:')\n",
        "# print(f'Accuracy: {results_gb[\"accuracy\"]}')\n",
        "# print(f'Precision: {results_gb[\"precision\"]}')\n",
        "# print(f'Recall: {results_gb[\"recall\"]}')\n",
        "# print(f'F1 Score: {results_gb[\"f1\"]}')\n",
        "# print('Classification Report:')\n",
        "# print(results_gb['classification_report'])\n",
        "\n",
        "# # Compare CV results\n",
        "# print(f'Cross-Validation Results for Random Forest: {results_rf[\"cv_results\"]}')\n",
        "# print(f'Cross-Validation Results for Gradient Boosting: {results_gb[\"cv_results\"]}')\n",
        "\n",
        "\n",
        "# # Run grid searches\n",
        "# results_rf = perform_grid_search(rf_model, param_grid_rf, X_train_top_3_smote, y_train_top_3_smote, X_test_top_3, y_test_top_3, n_jobs=n_cpus)\n",
        "# results_gb = perform_grid_search(gb_model, param_grid_gb, X_train_top_3_smote, y_train_top_3_smote, X_test_top_3, y_test_top_3, n_jobs=n_cpus)\n",
        "\n",
        "# from joblib import parallel_backend\n",
        "\n",
        "# # Assuming n_cpus is defined somewhere above\n",
        "# with parallel_backend('threading', n_jobs=n_cpus):\n",
        "#     results_rf = perform_grid_search(rf_model, param_grid_rf, X_train_top_3_smote,\n",
        "#                                       y_train_top_3_smote, X_test_top_3, y_test_top_3,\n",
        "#                                       n_jobs=n_cpus)\n",
        "#     results_gb = perform_grid_search(gb_model, param_grid_gb, X_train_top_3_smote,\n",
        "#                                       y_train_top_3_smote, X_test_top_3, y_test_top_3,\n",
        "#                                       n_jobs=n_cpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sheaxjhCKBqw"
      },
      "source": [
        "#### Code Debugging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uAveIdvFZ6l"
      },
      "source": [
        "There are several factors that could be causing your grid search with SMOTE to take longer than other grid searches. Here's a breakdown of the potential reasons and how to address them:\n",
        "\n",
        "1. SMOTE Itself:\n",
        "\n",
        "    Data Expansion: SMOTE (Synthetic Minority Over-sampling Technique) artificially generates new samples for the minority class. This increases the size of your training dataset, directly impacting the time it takes for your models to train during the grid search.\n",
        "\n",
        "2. Model Complexity:\n",
        "\n",
        "    Ensemble Methods: If you're using complex ensemble methods (like Random Forest, Gradient Boosting) within your grid search, the training time will naturally increase. These models often involve fitting multiple base estimators.\n",
        "    Hyperparameter Space: A larger hyperparameter search space (more parameters to tune and a wider range of values) means the grid search has to evaluate more combinations, leading to longer runtimes.\n",
        "\n",
        "3. Data Size:\n",
        "\n",
        "    Large Datasets: Even without SMOTE, larger datasets will always take longer to process. The combination of SMOTE and a large dataset can significantly amplify the training time.\n",
        "\n",
        "4. Hardware Limitations:\n",
        "\n",
        "    CPU/Memory Constraints: The speed of your computer's processor and the amount of available RAM directly affect how quickly the grid search can complete.\n",
        "\n",
        "How to Diagnose and Improve:\n",
        "\n",
        "    Time Profiling: Use Python's profiling tools (cProfile or line_profiler) to pinpoint the specific parts of your code that are consuming the most time. This will help you focus your optimization efforts.\n",
        "\n",
        "    SMOTE Variations: Experiment with different SMOTE variants or other oversampling techniques. Some might be more computationally efficient for your specific dataset.\n",
        "\n",
        "    Model Simplification: If possible, try simpler models or reduce the complexity of your ensemble methods (e.g., fewer trees in a Random Forest).\n",
        "\n",
        "    Hyperparameter Space Reduction: Carefully analyze your hyperparameter space. Are there any parameters you can fix or narrow down the range for?\n",
        "\n",
        "    Cross-Validation Folds: Reduce the number of cross-validation folds (the cv parameter in GridSearchCV) if it's feasible for your dataset.\n",
        "\n",
        "    Hardware Upgrade: If your resources are very limited, consider upgrading your hardware (more RAM, faster CPU) for a substantial performance boost.\n",
        "\n",
        "    Parallelization: If your hardware supports it, explore parallelizing your grid search\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Krn0qJWEFjje"
      },
      "outputs": [],
      "source": [
        "# import cProfile\n",
        "# cProfile.run('grid_search_top_3_smote.fit(X_train_top_3_smote, y_train_top_3_smote)', 'grid_search_stats')\n",
        "# import pstats\n",
        "#    p = pstats.Stats('grid_search_stats')\n",
        "#    p.sort_stats('cumulative').print_stats(20)  # Print top 20 most time-consuming functions\n",
        "#!pip install line_profiler\n",
        "# from line_profiler import LineProfiler\n",
        "\n",
        "#    def my_grid_search():\n",
        "#        grid_search_top_3_smote.fit(X_train_top_3_smote, y_train_top_3_smote)\n",
        "\n",
        "#    lp = LineProfiler()\n",
        "#    lp_wrapper = lp(my_grid_search)\n",
        "#    lp_wrapper()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6QBJmFZKKPE"
      },
      "source": [
        "### Champion Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85agsLGFkcsj"
      },
      "outputs": [],
      "source": [
        "# Best models\n",
        "best_model_top_10 = grid_search_top_10.best_estimator_\n",
        "best_model_top_3 = grid_search_top_3.best_estimator_\n",
        "best_model_top_3_smote = grid_search_top_3_smote.best_estimator_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztYsyBgVWeAn"
      },
      "source": [
        "## Prediction/Performance Evaluations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KERk5Pv2ifO7",
        "outputId": "45a34510-f9f7-48e3-b964-b7f0fe5ed639"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 10 Accuracy: 0.9968652037617555\n",
            "Top 10 Precision: 0.9970717423133236\n",
            "Top 10 Recall: 0.9956140350877193\n",
            "Top 10 F1 Score: 0.9963423555230432\n",
            "Top 10 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       1.00      1.00      1.00       911\n",
            "        True       1.00      1.00      1.00       684\n",
            "\n",
            "    accuracy                           1.00      1595\n",
            "   macro avg       1.00      1.00      1.00      1595\n",
            "weighted avg       1.00      1.00      1.00      1595\n",
            "\n",
            "Top 3 Accuracy: 0.9987460815047022\n",
            "Top 3 Precision: 1.0\n",
            "Top 3 Recall: 0.9905660377358491\n",
            "Top 3 F1 Score: 0.9952606635071091\n",
            "Top 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       1.00      1.00      1.00      1383\n",
            "        True       1.00      0.99      1.00       212\n",
            "\n",
            "    accuracy                           1.00      1595\n",
            "   macro avg       1.00      1.00      1.00      1595\n",
            "weighted avg       1.00      1.00      1.00      1595\n",
            "\n",
            "Top 3 with SMOTE Accuracy: 0.9993730407523511\n",
            "Top 3 with SMOTE Precision: 0.9953051643192489\n",
            "Top 3 with SMOTE Recall: 1.0\n",
            "Top 3 with SMOTE F1 Score: 0.9976470588235293\n",
            "Top 3 with SMOTE Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       1.00      1.00      1.00      1383\n",
            "        True       1.00      1.00      1.00       212\n",
            "\n",
            "    accuracy                           1.00      1595\n",
            "   macro avg       1.00      1.00      1.00      1595\n",
            "weighted avg       1.00      1.00      1.00      1595\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Predict and evaluate the model for top 10 finishes\n",
        "y_pred_top_10 = best_model_top_10.predict(X_test)\n",
        "accuracy_top_10 = accuracy_score(y_test_top_10, y_pred_top_10)\n",
        "precision_top_10 = precision_score(y_test_top_10, y_pred_top_10)\n",
        "recall_top_10 = recall_score(y_test_top_10, y_pred_top_10)\n",
        "f1_top_10 = f1_score(y_test_top_10, y_pred_top_10)\n",
        "class_report_top_10 = classification_report(y_test_top_10, y_pred_top_10)\n",
        "\n",
        "print(f'Top 10 Accuracy: {accuracy_top_10}')\n",
        "print(f'Top 10 Precision: {precision_top_10}')\n",
        "print(f'Top 10 Recall: {recall_top_10}')\n",
        "print(f'Top 10 F1 Score: {f1_top_10}')\n",
        "print('Top 10 Classification Report:')\n",
        "print(class_report_top_10)\n",
        "\n",
        "\n",
        "# Predict and evaluate the model for top 3 finishes\n",
        "y_pred_top_3 = best_model_top_3.predict(X_test_top_3)\n",
        "accuracy_top_3 = accuracy_score(y_test_top_3, y_pred_top_3)\n",
        "precision_top_3 = precision_score(y_test_top_3, y_pred_top_3)\n",
        "recall_top_3 = recall_score(y_test_top_3, y_pred_top_3)\n",
        "f1_top_3 = f1_score(y_test_top_3, y_pred_top_3)\n",
        "class_report_top_3 = classification_report(y_test_top_3, y_pred_top_3)\n",
        "\n",
        "print(f'Top 3 Accuracy: {accuracy_top_3}')\n",
        "print(f'Top 3 Precision: {precision_top_3}')\n",
        "print(f'Top 3 Recall: {recall_top_3}')\n",
        "print(f'Top 3 F1 Score: {f1_top_3}')\n",
        "print('Top 3 Classification Report:')\n",
        "print(class_report_top_3)\n",
        "\n",
        "# Predict and evaluate the model for top 3 finishes with SMOTE\n",
        "y_pred_top_3_smote = best_model_top_3_smote.predict(X_test_top_3)\n",
        "accuracy_top_3_smote = accuracy_score(y_test_top_3, y_pred_top_3_smote)\n",
        "precision_top_3_smote = precision_score(y_test_top_3, y_pred_top_3_smote)\n",
        "recall_top_3_smote = recall_score(y_test_top_3, y_pred_top_3_smote)\n",
        "f1_top_3_smote = f1_score(y_test_top_3, y_pred_top_3_smote)\n",
        "class_report_top_3_smote = classification_report(y_test_top_3, y_pred_top_3_smote)\n",
        "\n",
        "print(f'Top 3 with SMOTE Accuracy: {accuracy_top_3_smote}')\n",
        "print(f'Top 3 with SMOTE Precision: {precision_top_3_smote}')\n",
        "print(f'Top 3 with SMOTE Recall: {recall_top_3_smote}')\n",
        "print(f'Top 3 with SMOTE F1 Score: {f1_top_3_smote}')\n",
        "print('Top 3 with SMOTE Classification Report:')\n",
        "print(class_report_top_3_smote)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uofOaulJWlCz"
      },
      "source": [
        "# Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbtJlYhdDB2a",
        "outputId": "323ac901-4819-4f70-e1cd-fe6c87036a8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions for the next race:\n",
            "\n",
            "Top 10 Predictions:\n",
            "Will Hamilton place top 10: True\n",
            "Will Alonso place top 10: True\n",
            "Will Gasly place top 10: True\n",
            "Will Pérez place top 10: True\n",
            "Will Ricciardo place top 10: True\n",
            "Will Bottas place top 10: True\n",
            "Will Verstappen place top 10: True\n",
            "Will Sainz place top 10: True\n",
            "Will Ocon place top 10: False\n",
            "Will Stroll place top 10: False\n",
            "Will Leclerc place top 10: True\n",
            "Will Russell place top 10: True\n",
            "Will Tsunoda place top 10: False\n",
            "Will Zhou place top 10: False\n",
            "Will Piastri place top 10: True\n",
            "Will Bearman place top 10: True\n",
            "\n",
            "Top 3 Predictions:\n",
            "Will Hamilton place top 3: False\n",
            "Will Alonso place top 3: False\n",
            "Will Gasly place top 3: False\n",
            "Will Pérez place top 3: False\n",
            "Will Ricciardo place top 3: False\n",
            "Will Bottas place top 3: False\n",
            "Will Verstappen place top 3: False\n",
            "Will Sainz place top 3: False\n",
            "Will Ocon place top 3: False\n",
            "Will Stroll place top 3: False\n",
            "Will Leclerc place top 3: False\n",
            "Will Russell place top 3: False\n",
            "Will Tsunoda place top 3: False\n",
            "Will Zhou place top 3: False\n",
            "Will Piastri place top 3: False\n",
            "Will Bearman place top 3: False\n",
            "\n",
            "Top 3 SMOTE Predictions:\n",
            "Will Hamilton place top 3: False\n",
            "Will Alonso place top 3: False\n",
            "Will Gasly place top 3: False\n",
            "Will Pérez place top 3: False\n",
            "Will Ricciardo place top 3: False\n",
            "Will Bottas place top 3: False\n",
            "Will Verstappen place top 3: False\n",
            "Will Sainz place top 3: False\n",
            "Will Ocon place top 3: False\n",
            "Will Stroll place top 3: False\n",
            "Will Leclerc place top 3: False\n",
            "Will Russell place top 3: False\n",
            "Will Tsunoda place top 3: False\n",
            "Will Zhou place top 3: False\n",
            "Will Piastri place top 3: False\n",
            "Will Bearman place top 3: False\n"
          ]
        }
      ],
      "source": [
        "# Create a list of driver names\n",
        "driver_names = [\n",
        "    'Hamilton', 'Verstappen', 'Leclerc', 'Russell', 'Pérez', 'Piastri', 'Sainz', 'Bearman', 'Hulkenberg'\n",
        "    'Norris', 'Ricciardo', 'Alonso', 'Ocon', 'Gasly', 'Zhou', 'Bottas', 'Stroll', 'Tsunoda']\n",
        "\n",
        "# Get the driver IDs for the given driver names\n",
        "driver_ids = drivers[drivers['surname'].isin(driver_names)]['driverId'].tolist()\n",
        "\n",
        "# Get the driver IDs for the given driver names\n",
        "driver_ids = drivers[drivers['surname'].isin(driver_names)]['driverId'].tolist()\n",
        "driver_ids.remove(708)  # Remove 708\n",
        "driver_ids.remove(50)   # Remove 50\n",
        "\n",
        "# Initialize lists to store predictions for the next race\n",
        "predictions_top_10 = []\n",
        "predictions_top_3 = []\n",
        "predictions_top_3_smote = []\n",
        "\n",
        "# Loop through each driver and make predictions for the next race\n",
        "for driver_id in driver_ids:\n",
        "    driver_name = drivers[drivers['driverId'] == driver_id]['surname'].values[0]\n",
        "\n",
        "    # Get historical performance metrics\n",
        "    driver_results = results[results['driverId'] == driver_id]\n",
        "    driver_qualifying = qualifying[qualifying['driverId'] == driver_id]\n",
        "\n",
        "    # Calculate average starting grid position\n",
        "    avg_grid = driver_results['grid'].mean()\n",
        "\n",
        "    # Calculate average finishing position per season\n",
        "    avg_position_per_season = driver_results['positionOrder'].mean()\n",
        "\n",
        "    # Calculate average qualifying position\n",
        "    avg_qualifying_position = driver_qualifying['position'].mean()\n",
        "\n",
        "    # Calculate the team points for the team the driver is currently in\n",
        "    current_team_id = driver_results['constructorId'].values[-1]\n",
        "    avg_team_points = constructor_results[constructor_results['constructorId'] == current_team_id]['points'].mean()\n",
        "\n",
        "    # Calculate interaction features\n",
        "    qualifying_position_x_race_position = avg_grid * avg_position_per_season\n",
        "    qualifying_position_x_team_points = avg_grid * avg_team_points\n",
        "\n",
        "    # Calculate the number of top 10 and top 3 finishes for the driver overall\n",
        "    top_10_count = top_10_counts[top_10_counts['driverId'] == driver_id]['top_10_count'].values[0]\n",
        "    top_3_count = top_3_counts[top_3_counts['driverId'] == driver_id]['top_3_count'].values[0]\n",
        "\n",
        "    # Calculate average points per race\n",
        "    points_per_race = driver_results['points_per_race'].mean()\n",
        "\n",
        "    # Calculate average constructor points per race\n",
        "    constructor_points_per_race = driver_results['constructor_points_per_race'].mean()\n",
        "\n",
        "    # Calculate average driver standing\n",
        "    driver_standing = driver_results['driver_standing'].mean()\n",
        "\n",
        "    # Calculate average pit stop time and lap time\n",
        "    avg_pit_stop_time = driver_results['avg_pit_stop_time'].mean()\n",
        "    avg_lap_time = driver_results['avg_lap_time'].mean()\n",
        "\n",
        "    # Compile feature values into a DataFrame\n",
        "    driver_features = pd.DataFrame([{\n",
        "        'grid': avg_grid,\n",
        "        'avg_position_per_season': avg_position_per_season,\n",
        "        'avg_team_points': avg_team_points,\n",
        "        'avg_qualifying_position': avg_qualifying_position,\n",
        "        'qualifying_position_x_race_position': qualifying_position_x_race_position,\n",
        "        'qualifying_position_x_team_points': qualifying_position_x_team_points,\n",
        "        'points_per_race': points_per_race,\n",
        "        'constructor_points_per_race': constructor_points_per_race,\n",
        "        'driver_standing': driver_standing,\n",
        "        'top_10_count': top_10_count,\n",
        "        'top_3_count': top_3_count,\n",
        "        'avg_pit_stop_time': avg_pit_stop_time,\n",
        "        'avg_lap_time': avg_lap_time\n",
        "    }])\n",
        "\n",
        "    # Handle NaN values by replacing them with the mean of the column\n",
        "    #driver_features.fillna(driver_features.mean(), inplace=True) #still error\n",
        "    driver_features.fillna(0, inplace=True)\n",
        "\n",
        "    # Make predictions for top 10 and top 3 finishes\n",
        "    prediction_top_10 = best_model_top_10.predict(driver_features)[0]\n",
        "    prediction_top_3 = best_model_top_3.predict(driver_features)[0]\n",
        "    prediction_top_3_smote = best_model_top_3_smote.predict(driver_features)[0]\n",
        "\n",
        "    # Store predictions\n",
        "    predictions_top_10.append((driver_name, prediction_top_10))\n",
        "    predictions_top_3.append((driver_name, prediction_top_3))\n",
        "    predictions_top_3_smote.append((driver_name, prediction_top_3_smote))\n",
        "\n",
        "# Print predictions for all drivers\n",
        "print(\"Predictions for the next race:\")\n",
        "print(\"\\nTop 10 Predictions:\")\n",
        "for driver_name, pred_top_10 in predictions_top_10:\n",
        "    print(f\"Will {driver_name} place top 10: {pred_top_10}\")\n",
        "print(\"\\nTop 3 Predictions:\")\n",
        "for driver_name, pred_top_3 in predictions_top_3:\n",
        "    print(f\"Will {driver_name} place top 3: {pred_top_3}\")\n",
        "print(\"\\nTop 3 SMOTE Predictions:\")\n",
        "for driver_name, pred_top_3_smote in predictions_top_3_smote:\n",
        "    print(f\"Will {driver_name} place top 3: {pred_top_3}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sl2lJBR4Vnxb"
      },
      "source": [
        "### Stress Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZen0lr-SJRj",
        "outputId": "2f1369a2-27b4-482e-ad35-72eaa3b1619b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-Validation Scores for Top 10: [0.99874608 1.         0.99811912 0.99561129 0.99561129]\n",
            "Mean Cross-Validation Score for Top 10: 0.9976175548589342\n",
            "Cross-Validation Scores for Top 3: [0.97429467 1.         0.99874608 0.99122257 0.96802508]\n",
            "Mean Cross-Validation Score for Top 3: 0.9864576802507837\n",
            "Cross-Validation Scores for Top 3 SMOTE: [0.97241379 1.         0.99874608 0.99122257 0.96802508]\n",
            "Mean Cross-Validation Score for Top 3 SMOTE: 0.9860815047021945\n",
            "Train-Test Accuracies for Top 10: {0.1: 1.0, 0.3: 0.9991642290012537, 0.4: 0.9996865203761756}\n",
            "Train-Test Accuracies for Top 3: {0.1: 1.0, 0.3: 0.9995821145006268, 0.4: 0.9987460815047022}\n",
            "Train-Test Accuracies for Top 3 SMOTE: {0.1: 1.0, 0.3: 0.9991642290012537, 0.4: 0.9987460815047022}\n"
          ]
        }
      ],
      "source": [
        "# Perform 5-fold cross-validation for top 10 and top 3 models\n",
        "cv_scores_top_10 = cross_val_score(best_model_top_10, features, target_top_10, cv=5, scoring='accuracy')\n",
        "cv_scores_top_3 = cross_val_score(best_model_top_3, features, target_top_3, cv=5, scoring='accuracy')\n",
        "cv_scores_top_3_smote = cross_val_score(best_model_top_3_smote, features, target_top_3, cv=5, scoring='accuracy')\n",
        "\n",
        "print(f'Cross-Validation Scores for Top 10: {cv_scores_top_10}')\n",
        "print(f'Mean Cross-Validation Score for Top 10: {cv_scores_top_10.mean()}')\n",
        "print(f'Cross-Validation Scores for Top 3: {cv_scores_top_3}')\n",
        "print(f'Mean Cross-Validation Score for Top 3: {cv_scores_top_3.mean()}')\n",
        "print(f'Cross-Validation Scores for Top 3 SMOTE: {cv_scores_top_3_smote}')\n",
        "print(f'Mean Cross-Validation Score for Top 3 SMOTE: {cv_scores_top_3_smote.mean()}')\n",
        "\n",
        "# Additional Train-Test Splits for top 10 model\n",
        "test_sizes = [0.1, 0.3, 0.4]\n",
        "train_test_accuracies_top_10 = {}\n",
        "for test_size in test_sizes:\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, target_top_10, test_size=test_size, random_state=42)\n",
        "    best_model_top_10.fit(X_train, y_train)\n",
        "    y_pred = best_model_top_10.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    train_test_accuracies_top_10[test_size] = accuracy\n",
        "\n",
        "# Additional Train-Test Splits for top 3 model\n",
        "train_test_accuracies_top_3 = {}\n",
        "for test_size in test_sizes:\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, target_top_3, test_size=test_size, random_state=42)\n",
        "    best_model_top_3.fit(X_train, y_train)\n",
        "    y_pred = best_model_top_3.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    train_test_accuracies_top_3[test_size] = accuracy\n",
        "\n",
        "\n",
        "\n",
        "# Additional Train-Test Splits for top 3 SMOTE model\n",
        "train_test_accuracies_top_3_smote = {}\n",
        "for test_size in test_sizes:\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, target_top_3, test_size=test_size, random_state=42)\n",
        "    best_model_top_3_smote.fit(X_train, y_train)\n",
        "    y_pred = best_model_top_3_smote.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    train_test_accuracies_top_3_smote[test_size] = accuracy\n",
        "\n",
        "print(f'Train-Test Accuracies for Top 10: {train_test_accuracies_top_10}')\n",
        "print(f'Train-Test Accuracies for Top 3: {train_test_accuracies_top_3}')\n",
        "print(f'Train-Test Accuracies for Top 3 SMOTE: {train_test_accuracies_top_3_smote}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmJmWLyrSguI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "# Add noise to the features for robustness check\n",
        "features_noisy_top_10 = features.copy()\n",
        "noise_top_10 = np.random.normal(0, 0.1, features.shape)\n",
        "features_noisy_top_10 += noise_top_10\n",
        "\n",
        "# Split the noisy data for top 10 model\n",
        "X_train, X_test, y_train, y_test = train_test_split(features_noisy_top_10, target_top_10, test_size=0.2, random_state=42)\n",
        "best_model_top_10.fit(X_train, y_train)\n",
        "y_pred = best_model_top_10.predict(X_test)\n",
        "accuracy_noisy_top_10 = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Add noise to the features for robustness check\n",
        "features_noisy_top_3 = features.copy()\n",
        "noise_top_3 = np.random.normal(0, 0.1, features.shape)\n",
        "features_noisy_top_3 += noise_top_3\n",
        "\n",
        "# Split the noisy data for top 3 model\n",
        "X_train, X_test, y_train, y_test = train_test_split(features_noisy_top_3, target_top_3, test_size=0.2, random_state=42)\n",
        "best_model_top_3.fit(X_train, y_train)\n",
        "y_pred = best_model_top_3.predict(X_test)\n",
        "accuracy_noisy_top_3 = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Add noise to the features for robustness check\n",
        "features_noisy_top_3_smote = features.copy()\n",
        "noise_top_3_smote = np.random.normal(0, 0.1, features.shape)\n",
        "features_noisy_top_3_smote += noise_top_3_smote\n",
        "\n",
        "# Split the noisy data for top 3 model\n",
        "X_train, X_test, y_train, y_test = train_test_split(features_noisy_top_3, target_top_3, test_size=0.2, random_state=42)\n",
        "best_model_top_3_smote.fit(X_train, y_train)\n",
        "y_pred = best_model_top_3_smote.predict(X_test)\n",
        "accuracy_noisy_top_3_smote = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy for Top 10 with Noisy Data: {accuracy_noisy_top_10}')\n",
        "print(f'Accuracy for Top 3 with Noisy Data: {accuracy_noisy_top_3}')\n",
        "print(f'Accuracy for Top 3 SMOTE with Noisy Data: {accuracy_noisy_top_3_smote}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqto-pPoVhjZ"
      },
      "source": [
        "### Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHLsNEUBDFKt"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Check feature importances for the best models\n",
        "rf_importances = best_model_top_10.named_estimators_['rf'].feature_importances_\n",
        "gb_importances = best_model_top_10.named_estimators_['gb'].feature_importances_\n",
        "\n",
        "# Create a DataFrame for feature importances\n",
        "feature_names = features.columns\n",
        "importances_df = pd.DataFrame({'Feature': feature_names, 'RandomForest': rf_importances, 'GradientBoosting': gb_importances})\n",
        "\n",
        "print(importances_df.sort_values(by='RandomForest', ascending=False))\n",
        "print(importances_df.sort_values(by='GradientBoosting', ascending=False))\n",
        "\n",
        "importances_df.plot(kind='bar', figsize=(12, 8), title='Feature Importances')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0pFyV7FRWp7"
      },
      "outputs": [],
      "source": [
        "# prompt: sort these as well\n",
        "# importances_df.plot(kind='bar', figsize=(12, 8), title='Feature Importances')\n",
        "# plt.show()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "importances_df.sort_values(by=['RandomForest', 'GradientBoosting'], ascending=False).plot(kind='bar', figsize=(12, 8), title='Feature Importances')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvsv8KrOXBWG"
      },
      "source": [
        "# Summary\n",
        "\n",
        "This model has high accuracy leading me to think there is some overfitting and may need rework soon."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HMBg1u3XILF"
      },
      "outputs": [],
      "source": [
        "# Predict and evaluate the model for top 10 finishes\n",
        "y_pred_top_10 = best_model_top_10.predict(X_test)\n",
        "accuracy_top_10 = accuracy_score(y_test_top_10, y_pred_top_10)\n",
        "precision_top_10 = precision_score(y_test_top_10, y_pred_top_10)\n",
        "recall_top_10 = recall_score(y_test_top_10, y_pred_top_10)\n",
        "f1_top_10 = f1_score(y_test_top_10, y_pred_top_10)\n",
        "class_report_top_10 = classification_report(y_test_top_10, y_pred_top_10)\n",
        "\n",
        "print(f'Top 10 Accuracy: {accuracy_top_10}')\n",
        "print(f'Top 10 Precision: {precision_top_10}')\n",
        "print(f'Top 10 Recall: {recall_top_10}')\n",
        "print(f'Top 10 F1 Score: {f1_top_10}')\n",
        "print('Top 10 Classification Report:')\n",
        "print(class_report_top_10)\n",
        "\n",
        "# Predict and evaluate the model for top 3 finishes\n",
        "y_pred_top_3 = best_model_top_3.predict(X_test_top_3)\n",
        "accuracy_top_3 = accuracy_score(y_test_top_3, y_pred_top_3)\n",
        "precision_top_3 = precision_score(y_test_top_3, y_pred_top_3)\n",
        "recall_top_3 = recall_score(y_test_top_3, y_pred_top_3)\n",
        "f1_top_3 = f1_score(y_test_top_3, y_pred_top_3)\n",
        "class_report_top_3 = classification_report(y_test_top_3, y_pred_top_3)\n",
        "\n",
        "print(f'Top 3 Accuracy: {accuracy_top_3}')\n",
        "print(f'Top 3 Precision: {precision_top_3}')\n",
        "print(f'Top 3 Recall: {recall_top_3}')\n",
        "print(f'Top 3 F1 Score: {f1_top_3}')\n",
        "print('Top 3 Classification Report:')\n",
        "print(class_report_top_3)\n",
        "\n",
        "# Predict and evaluate the model for top 3 finishes with SMOTE\n",
        "y_pred_top_3_smote = best_model_top_3_smote.predict(X_test_top_3)\n",
        "accuracy_top_3_smote = accuracy_score(y_test_top_3, y_pred_top_3_smote)\n",
        "precision_top_3_smote = precision_score(y_test_top_3, y_pred_top_3_smote)\n",
        "recall_top_3_smote = recall_score(y_test_top_3, y_pred_top_3_smote)\n",
        "f1_top_3_smote = f1_score(y_test_top_3, y_pred_top_3_smote)\n",
        "class_report_top_3_smote = classification_report(y_test_top_3, y_pred_top_3_smote)\n",
        "\n",
        "print(f'Top 3 with SMOTE Accuracy: {accuracy_top_3_smote}')\n",
        "print(f'Top 3 with SMOTE Precision: {precision_top_3_smote}')\n",
        "print(f'Top 3 with SMOTE Recall: {recall_top_3_smote}')\n",
        "print(f'Top 3 with SMOTE F1 Score: {f1_top_3_smote}')\n",
        "print('Top 3 with SMOTE Classification Report:')\n",
        "print(class_report_top_3_smote)\n",
        "\n",
        "# Perform 5-fold cross-validation for top 10 and top 3 models\n",
        "cv_scores_top_10 = cross_val_score(best_model_top_10, features, target_top_10, cv=5, scoring='accuracy')\n",
        "cv_scores_top_3 = cross_val_score(best_model_top_3, features, target_top_3, cv=5, scoring='accuracy')\n",
        "\n",
        "print(f'Cross-Validation Scores for Top 10: {cv_scores_top_10}')\n",
        "print(f'Mean Cross-Validation Score for Top 10: {cv_scores_top_10.mean()}')\n",
        "print(f'Cross-Validation Scores for Top 3: {cv_scores_top_3}')\n",
        "print(f'Mean Cross-Validation Score for Top 3: {cv_scores_top_3.mean()}')\n",
        "\n",
        "# Perform 5-fold cross-validation for top 3 SMOTE model\n",
        "cv_scores_top_3_smote = cross_val_score(best_model_top_3_smote, features, target_top_3, cv=5, scoring='accuracy')\n",
        "print(f'Cross-Validation Scores for Top 3 SMOTE: {cv_scores_top_3_smote}')\n",
        "print(f'Mean Cross-Validation Score for Top 3 SMOTE: {cv_scores_top_3_smote.mean()}')\n",
        "\n",
        "# Additional Train-Test Splits for top 10 model\n",
        "test_sizes = [0.1, 0.3, 0.4]\n",
        "train_test_accuracies_top_10 = {}\n",
        "for test_size in test_sizes:\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, target_top_10, test_size=test_size, random_state=42)\n",
        "    best_model_top_10.fit(X_train, y_train)\n",
        "    y_pred = best_model_top_10.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    train_test_accuracies_top_10[test_size] = accuracy\n",
        "\n",
        "# Additional Train-Test Splits for top 3 model\n",
        "train_test_accuracies_top_3 = {}\n",
        "for test_size in test_sizes:\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, target_top_3, test_size=test_size, random_state=42)\n",
        "    best_model_top_3.fit(X_train, y_train)\n",
        "    y_pred = best_model_top_3.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    train_test_accuracies_top_3[test_size] = accuracy\n",
        "\n",
        "print(f'Train-Test Accuracies for Top 10: {train_test_accuracies_top_10}')\n",
        "print(f'Train-Test Accuracies for Top 3: {train_test_accuracies_top_3}')\n",
        "\n",
        "# Add noise to the features for robustness check\n",
        "features_noisy_top_10 = features.copy()\n",
        "noise_top_10 = np.random.normal(0, 0.1, features.shape)\n",
        "features_noisy_top_10 += noise_top_10\n",
        "\n",
        "# Split the noisy data for top 10 model\n",
        "X_train, X_test, y_train, y_test = train_test_split(features_noisy_top_10, target_top_10, test_size=0.2, random_state=42)\n",
        "best_model_top_10.fit(X_train, y_train)\n",
        "y_pred = best_model_top_10.predict(X_test)\n",
        "accuracy_noisy_top_10 = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Add noise to the features for robustness check\n",
        "features_noisy_top_3 = features.copy()\n",
        "noise_top_3 = np.random.normal(0, 0.1, features.shape)\n",
        "features_noisy_top_3 += noise_top_3\n",
        "\n",
        "# Split the noisy data for top 3 model\n",
        "X_train, X_test, y_train, y_test = train_test_split(features_noisy_top_3, target_top_3, test_size=0.2, random_state=42)\n",
        "best_model_top_3.fit(X_train, y_train)\n",
        "y_pred = best_model_top_3.predict(X_test)\n",
        "accuracy_noisy_top_3 = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Split the noisy data for top 3 SMOTE model\n",
        "X_train_smote, X_test_smote, y_train_smote, y_test_smote = train_test_split(features_noisy_top_3, target_top_3, test_size=0.2, random_state=42)\n",
        "best_model_top_3_smote.fit(X_train_smote, y_train_smote)\n",
        "y_pred_smote = best_model_top_3_smote.predict(X_test_smote)\n",
        "accuracy_noisy_top_3_smote = accuracy_score(y_test_smote, y_pred_smote)\n",
        "\n",
        "print(f'Accuracy for Top 10 with Noisy Data: {accuracy_noisy_top_10}')\n",
        "print(f'Accuracy for Top 3 with Noisy Data: {accuracy_noisy_top_3}')\n",
        "print(f'Accuracy for Top 3 SMOTE with Noisy Data: {accuracy_noisy_top_3_smote}')\n",
        "\n",
        "# Print feature importances\n",
        "rf_importances = best_model_top_10.named_estimators_['rf'].feature_importances_\n",
        "gb_importances = best_model_top_10.named_estimators_['gb'].feature_importances_\n",
        "\n",
        "# Create a DataFrame for feature importances\n",
        "feature_names = features.columns\n",
        "importances_df = pd.DataFrame({'Feature': feature_names, 'RandomForest': rf_importances, 'GradientBoosting': gb_importances})\n",
        "\n",
        "print(importances_df.sort_values(by='RandomForest', ascending=False))\n",
        "print(importances_df.sort_values(by='GradientBoosting', ascending=False))\n",
        "\n",
        "importances_df.plot(kind='bar', figsize=(12, 8), title='Feature Importances')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iWjuSXzX4b0"
      },
      "source": [
        "# Logistics and Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezCxUO8NXXEl"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "# from imblearn.over_sampling import SMOTE\n",
        "# import multiprocessing\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# Suppress SettingWithCopyWarning\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "\n",
        "# Load your datasets (ensure the file paths are correct)\n",
        "# drivers = pd.read_csv('drivers.csv')\n",
        "# qualifying = pd.read_csv('qualifying.csv')\n",
        "# races = pd.read_csv('races.csv')\n",
        "# lap_times = pd.read_csv('lap_times.csv')\n",
        "# pit_stop_times = pd.read_csv('pit_stops.csv')\n",
        "# driver_standings = pd.read_csv('driver_standings.csv')\n",
        "results = pd.read_csv('results.csv')\n",
        "# status = pd.read_csv('status.csv')\n",
        "# constructor_results = pd.read_csv('constructor_results.csv')\n",
        "# constructor_standings = pd.read_csv('constructor_standings.csv')\n",
        "\n",
        "# Identify drivers who finished the races\n",
        "finished_status_ids = status[status['status'].str.lower().isin(['finished', '1', 'active'])]['statusId'].unique()\n",
        "finished_results = results[results['statusId'].isin(finished_status_ids)]\n",
        "\n",
        "# Identify drivers who finished in the top 10 positions\n",
        "finished_results['top_10'] = finished_results['positionOrder'] <= 10\n",
        "\n",
        "# Merge races and results to get race year\n",
        "results = results.merge(races[['raceId', 'year']], on='raceId', how='left')\n",
        "\n",
        "# Calculate average position per season for each driver\n",
        "seasonal_performance = results.groupby(['driverId', 'year'])['positionOrder'].mean().reset_index()\n",
        "seasonal_performance.columns = ['driverId', 'year', 'avg_position_per_season']\n",
        "\n",
        "# Function to convert time\n",
        "def convert_time(time_str):\n",
        "    try:\n",
        "        if time_str == '\\\\N':\n",
        "            return 999 * 60 + 59.999\n",
        "        mins, secs = time_str.split(':')\n",
        "        return int(mins) * 60 + float(secs)\n",
        "    except:\n",
        "        return 999 * 60 + 59.999\n",
        "\n",
        "# Calculate average qualifying position for each driver\n",
        "qualifying['q1'] = qualifying['q1'].fillna('999:59.999').apply(convert_time)\n",
        "qualifying['q2'] = qualifying['q2'].fillna('999:59.999').apply(convert_time)\n",
        "qualifying['q3'] = qualifying['q3'].fillna('999:59.999').apply(convert_time)\n",
        "qualifying['qualifying_time'] = (\n",
        "    qualifying['q1'] + qualifying['q2'] + qualifying['q3']\n",
        ") / qualifying[['q1', 'q2', 'q3']].notna().sum(axis=1)\n",
        "avg_qualifying_position = qualifying.groupby('driverId')['position'].mean().reset_index()\n",
        "avg_qualifying_position.columns = ['driverId', 'avg_qualifying_position']\n",
        "\n",
        "# Calculate average team points\n",
        "avg_team_points = constructor_results.groupby('constructorId')['points'].mean().reset_index()\n",
        "avg_team_points.columns = ['constructorId', 'avg_team_points']\n",
        "\n",
        "# Merge all performance metrics into results dataframe\n",
        "results = results.merge(seasonal_performance, on=['driverId', 'year'], how='left')\n",
        "results = results.merge(avg_qualifying_position, on='driverId', how='left')\n",
        "results = results.merge(avg_team_points, on='constructorId', how='left')\n",
        "\n",
        "# Create interaction features\n",
        "results['qualifying_position_x_race_position'] = results['grid'] * results['positionOrder']\n",
        "results['qualifying_position_x_team_points'] = results['grid'] * results['avg_team_points']\n",
        "\n",
        "# Ensure the target variable exists\n",
        "results['top_10'] = results['positionOrder'] <= 10\n",
        "results['top_3'] = results['positionOrder'] <= 3\n",
        "\n",
        "# Additional feature engineering\n",
        "results['points_per_race'] = results['points'] / results['raceId'].map(results.groupby('raceId')['raceId'].count())\n",
        "results['constructor_points_per_race'] = results['constructorId'].map(constructor_results.groupby('constructorId')['points'].mean())\n",
        "results['driver_standing'] = results['driverId'].map(driver_standings.groupby('driverId')['points'].mean())\n",
        "results['avg_pit_stop_time'] = pit_stop_times.groupby('raceId')['milliseconds'].transform('mean') / 1000  # converting ms to seconds\n",
        "results['avg_lap_time'] = lap_times.groupby('raceId')['milliseconds'].transform('mean') / 1000  # converting ms to seconds\n",
        "\n",
        "# Calculate the number of top 10 and top 3 finishes for each driver\n",
        "top_10_counts = results.groupby('driverId')['top_10'].sum().reset_index()\n",
        "top_3_counts = results.groupby('driverId')['top_3'].sum().reset_index()\n",
        "\n",
        "top_10_counts.columns = ['driverId', 'top_10_count']\n",
        "top_3_counts.columns = ['driverId', 'top_3_count']\n",
        "\n",
        "results = results.merge(top_10_counts, on='driverId', how='left')\n",
        "results = results.merge(top_3_counts, on='driverId', how='left')\n",
        "\n",
        "# Prepare the data for training\n",
        "features = results[['grid', 'avg_position_per_season', 'avg_team_points', 'avg_qualifying_position',\n",
        "                    'qualifying_position_x_race_position', 'qualifying_position_x_team_points',\n",
        "                    'points_per_race', 'constructor_points_per_race', 'driver_standing',\n",
        "                    'top_10_count', 'top_3_count', 'avg_pit_stop_time', 'avg_lap_time']]\n",
        "target_top_10 = results['top_10']\n",
        "target_top_3 = results['top_3']\n",
        "\n",
        "# Drop any rows with missing values\n",
        "features = features.dropna()\n",
        "target_top_10 = target_top_10[features.index]\n",
        "target_top_3 = target_top_3[features.index]\n",
        "\n",
        "# Split the data into training and testing sets for both targets\n",
        "X_train, X_test, y_train_top_10, y_test_top_10 = train_test_split(features, target_top_10, test_size=0.2, random_state=42)\n",
        "X_train_top_3, X_test_top_3, y_train_top_3, y_test_top_3 = train_test_split(features, target_top_3, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply SMOTE to handle class imbalance for top 3 predictions\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_top_3_smote, y_train_top_3_smote = smote.fit_resample(X_train_top_3, y_train_top_3)\n",
        "\n",
        "# Use a simpler model for comparison\n",
        "lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
        "\n",
        "# Train the models\n",
        "lr_model_top_10 = lr_model.fit(X_train, y_train_top_10)\n",
        "lr_model_top_3 = lr_model.fit(X_train_top_3, y_train_top_3)\n",
        "lr_model_top_3_smote = lr_model.fit(X_train_top_3_smote, y_train_top_3_smote)\n",
        "\n",
        "# Evaluate the models\n",
        "y_pred_top_10 = lr_model_top_10.predict(X_test)\n",
        "y_pred_top_3 = lr_model_top_3.predict(X_test_top_3)\n",
        "y_pred_top_3_smote = lr_model_top_3_smote.predict(X_test_top_3)\n",
        "\n",
        "print('Logistic Regression Model - Top 10')\n",
        "print(f'Accuracy: {accuracy_score(y_test_top_10, y_pred_top_10)}')\n",
        "print(f'Precision: {precision_score(y_test_top_10, y_pred_top_10)}')\n",
        "print(f'Recall: {recall_score(y_test_top_10, y_pred_top_10)}')\n",
        "print(f'F1 Score: {f1_score(y_test_top_10, y_pred_top_10)}')\n",
        "print('Classification Report:')\n",
        "print(classification_report(y_test_top_10, y_pred_top_10))\n",
        "\n",
        "print('Logistic Regression Model - Top 3')\n",
        "print(f'Accuracy: {accuracy_score(y_test_top_3, y_pred_top_3)}')\n",
        "print(f'Precision: {precision_score(y_test_top_3, y_pred_top_3)}')\n",
        "print(f'Recall: {recall_score(y_test_top_3, y_pred_top_3)}')\n",
        "print(f'F1 Score: {f1_score(y_test_top_3, y_pred_top_3)}')\n",
        "print('Classification Report:')\n",
        "print(classification_report(y_test_top_3, y_pred_top_3))\n",
        "\n",
        "print('Logistic Regression Model - Top 3 with SMOTE')\n",
        "print(f'Accuracy: {accuracy_score(y_test_top_3, y_pred_top_3_smote)}')\n",
        "print(f'Precision: {precision_score(y_test_top_3, y_pred_top_3_smote)}')\n",
        "print(f'Recall: {recall_score(y_test_top_3, y_pred_top_3_smote)}')\n",
        "print(f'F1 Score: {f1_score(y_test_top_3, y_pred_top_3_smote)}')\n",
        "print('Classification Report:')\n",
        "print(classification_report(y_test_top_3, y_pred_top_3_smote))\n",
        "\n",
        "# Perform 5-fold cross-validation for top 10 and top 3 models\n",
        "cv_scores_top_10 = cross_val_score(lr_model, features, target_top_10, cv=5, scoring='accuracy')\n",
        "cv_scores_top_3 = cross_val_score(lr_model, features, target_top_3, cv=5, scoring='accuracy')\n",
        "cv_scores_top_3_smote = cross_val_score(lr_model, X_train_top_3_smote, y_train_top_3_smote, cv=5, scoring='accuracy')\n",
        "\n",
        "print(f'Cross-Validation Scores for Top 10: {cv_scores_top_10}')\n",
        "print(f'Mean Cross-Validation Score for Top 10: {cv_scores_top_10.mean()}')\n",
        "print(f'Cross-Validation Scores for Top 3: {cv_scores_top_3}')\n",
        "print(f'Mean Cross-Validation Score for Top 3: {cv_scores_top_3.mean()}')\n",
        "print(f'Cross-Validation Scores for Top 3 SMOTE: {cv_scores_top_3_smote}')\n",
        "print(f'Mean Cross-Validation Score for Top 3 SMOTE: {cv_scores_top_3_smote.mean()}')\n",
        "\n",
        "# Additional Train-Test Splits for top 10 model\n",
        "test_sizes = [0.1, 0.3, 0.4]\n",
        "train_test_accuracies_top_10 = {}\n",
        "for test_size in test_sizes:\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, target_top_10, test_size=test_size, random_state=42)\n",
        "    lr_model.fit(X_train, y_train)\n",
        "    y_pred = lr_model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    train_test_accuracies_top_10[test_size] = accuracy\n",
        "\n",
        "# Additional Train-Test Splits for top 3 model\n",
        "train_test_accuracies_top_3 = {}\n",
        "for test_size in test_sizes:\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, target_top_3, test_size=test_size, random_state=42)\n",
        "    lr_model.fit(X_train, y_train)\n",
        "    y_pred = lr_model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    train_test_accuracies_top_3[test_size] = accuracy\n",
        "\n",
        "print(f'Train-Test Accuracies for Top 10: {train_test_accuracies_top_10}')\n",
        "print(f'Train-Test Accuracies for Top 3: {train_test_accuracies_top_3}')\n",
        "\n",
        "# Add noise to the features for robustness check\n",
        "features_noisy_top_10 = features.copy()\n",
        "noise_top_10 = np.random.normal(0, 0.1, features.shape)\n",
        "features_noisy_top_10 += noise_top_10\n",
        "\n",
        "# Split the noisy data for top 10 model\n",
        "X_train, X_test, y_train, y_test = train_test_split(features_noisy_top_10, target_top_10, test_size=0.2, random_state=42)\n",
        "lr_model.fit(X_train, y_train)\n",
        "y_pred = lr_model.predict(X_test)\n",
        "accuracy_noisy_top_10 = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Add noise to the features for robustness check\n",
        "features_noisy_top_3 = features.copy()\n",
        "noise_top_3 = np.random.normal(0, 0.1, features.shape)\n",
        "features_noisy_top_3 += noise_top_3\n",
        "\n",
        "# Split the noisy data for top 3 model\n",
        "X_train, X_test, y_train, y_test = train_test_split(features_noisy_top_3, target_top_3, test_size=0.2, random_state=42)\n",
        "lr_model.fit(X_train, y_train)\n",
        "y_pred = lr_model.predict(X_test)\n",
        "accuracy_noisy_top_3 = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Split the noisy data for top 3 SMOTE model\n",
        "X_train_smote, X_test_smote, y_train_smote, y_test_smote = train_test_split(features_noisy_top_3, target_top_3, test_size=0.2, random_state=42)\n",
        "lr_model.fit(X_train_smote, y_train_smote)\n",
        "y_pred_smote = lr_model.predict(X_test_smote)\n",
        "accuracy_noisy_top_3_smote = accuracy_score(y_test_smote, y_pred_smote)\n",
        "\n",
        "print(f'Accuracy for Top 10 with Noisy Data: {accuracy_noisy_top_10}')\n",
        "print(f'Accuracy for Top 3 with Noisy Data: {accuracy_noisy_top_3}')\n",
        "print(f'Accuracy for Top 3 SMOTE with Noisy Data: {accuracy_noisy_top_3_smote}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOtIDu0SYJGz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "sheaxjhCKBqw"
      ],
      "toc_visible": true,
      "provenance": [],
      "authorship_tag": "ABX9TyN4e8OiIXCoCg8QdTUKzSRl",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}