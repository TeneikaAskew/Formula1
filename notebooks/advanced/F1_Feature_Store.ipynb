{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1 Feature Store\n",
    "\n",
    "This notebook develops a comprehensive feature store for F1 predictions, including:\n",
    "- Weather data integration (simulated)\n",
    "- Momentum indicators\n",
    "- Track characteristics\n",
    "- Team strategy patterns\n",
    "- Advanced performance metrics\n",
    "\n",
    "The feature store provides a centralized, reusable set of features for all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "from enhanced_f1db_data_loader import load_f1db_data_enhanced\n",
    "\n",
    "print(\"Loading F1 data...\")\n",
    "f1_data = load_f1db_data_enhanced(data_dir='../../data/f1db', auto_sync=True)\n",
    "\n",
    "# Get all necessary datasets\n",
    "results = f1_data.get('results', pd.DataFrame())\n",
    "races = f1_data.get('races', pd.DataFrame())\n",
    "drivers = f1_data.get('drivers', pd.DataFrame())\n",
    "constructors = f1_data.get('constructors', pd.DataFrame())\n",
    "qualifying = f1_data.get('qualifying', pd.DataFrame())\n",
    "circuits = f1_data.get('circuits', pd.DataFrame())\n",
    "lap_times = f1_data.get('lap_times', pd.DataFrame())\n",
    "pit_stops = f1_data.get('pit_stops', pd.DataFrame())\n",
    "driver_standings = f1_data.get('driver_standings', pd.DataFrame())\n",
    "constructor_standings = f1_data.get('constructor_standings', pd.DataFrame())\n",
    "status = f1_data.get('status', pd.DataFrame())\n",
    "\n",
    "print(f\"Loaded {len(f1_data)} datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Base Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create base dataframe with all race results\n",
    "df_base = results.merge(races[['raceId', 'year', 'round', 'circuitId', 'date', 'name']], on='raceId')\n",
    "df_base = df_base.merge(drivers[['driverId', 'driverRef', 'surname', 'code', 'dob']], on='driverId')\n",
    "df_base = df_base.merge(constructors[['constructorId', 'constructorRef', 'name']], \n",
    "                       on='constructorId', suffixes=('_race', '_constructor'))\n",
    "df_base = df_base.merge(circuits[['circuitId', 'circuitRef', 'location', 'country', 'lat', 'lng']], \n",
    "                       on='circuitId')\n",
    "\n",
    "# Convert dates\n",
    "df_base['date'] = pd.to_datetime(df_base['date'])\n",
    "df_base['dob'] = pd.to_datetime(df_base['dob'])\n",
    "df_base['driver_age'] = (df_base['date'] - df_base['dob']).dt.days / 365.25\n",
    "\n",
    "# Sort by date\n",
    "df_base = df_base.sort_values(['date', 'raceId', 'positionOrder'])\n",
    "\n",
    "print(f\"Base dataframe shape: {df_base.shape}\")\n",
    "print(f\"Date range: {df_base['date'].min()} to {df_base['date'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Track Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_track_features(df, circuits):\n",
    "    \"\"\"\n",
    "    Create track characteristic features\n",
    "    \"\"\"\n",
    "    # Calculate track statistics\n",
    "    track_stats = df.groupby('circuitId').agg({\n",
    "        'positionOrder': ['mean', 'std'],\n",
    "        'statusId': lambda x: (x > 1).mean(),  # DNF rate\n",
    "        'laps': 'mean',\n",
    "        'milliseconds': 'mean',\n",
    "        'points': 'mean'\n",
    "    }).round(3)\n",
    "    \n",
    "    track_stats.columns = ['avg_position', 'position_variance', 'dnf_rate', \n",
    "                           'avg_laps', 'avg_race_time', 'avg_points']\n",
    "    \n",
    "    # Add circuit information\n",
    "    track_features = circuits.merge(track_stats, left_on='circuitId', right_index=True, how='left')\n",
    "    \n",
    "    # Categorize tracks based on characteristics\n",
    "    # Street circuits (Monaco, Singapore, etc.)\n",
    "    street_circuits = ['monaco', 'singapore', 'adelaide', 'detroit', 'phoenix', \n",
    "                      'dallas', 'las_vegas', 'baku', 'sochi', 'valencia']\n",
    "    track_features['is_street_circuit'] = track_features['circuitRef'].str.lower().isin(street_circuits).astype(int)\n",
    "    \n",
    "    # High-speed circuits (Monza, Spa, etc.)\n",
    "    high_speed_circuits = ['monza', 'spa', 'silverstone', 'suzuka', 'interlagos']\n",
    "    track_features['is_high_speed'] = track_features['circuitRef'].str.lower().isin(high_speed_circuits).astype(int)\n",
    "    \n",
    "    # Technical circuits (Monaco, Hungary, etc.)\n",
    "    technical_circuits = ['monaco', 'hungaroring', 'marina_bay', 'catalunya']\n",
    "    track_features['is_technical'] = track_features['circuitRef'].str.lower().isin(technical_circuits).astype(int)\n",
    "    \n",
    "    # Altitude effect (Mexico City, Interlagos, Red Bull Ring)\n",
    "    high_altitude_circuits = ['rodriguez', 'interlagos', 'red_bull_ring']\n",
    "    track_features['is_high_altitude'] = track_features['circuitRef'].str.lower().isin(high_altitude_circuits).astype(int)\n",
    "    \n",
    "    # Calculate overtaking difficulty index based on position changes\n",
    "    position_changes = []\n",
    "    for circuit_id in df['circuitId'].unique():\n",
    "        circuit_races = df[df['circuitId'] == circuit_id]\n",
    "        \n",
    "        # Calculate average position change from grid to finish\n",
    "        avg_position_change = np.abs(circuit_races['grid'] - circuit_races['positionOrder']).mean()\n",
    "        position_changes.append({\n",
    "            'circuitId': circuit_id,\n",
    "            'overtaking_index': avg_position_change\n",
    "        })\n",
    "    \n",
    "    overtaking_df = pd.DataFrame(position_changes)\n",
    "    track_features = track_features.merge(overtaking_df, on='circuitId', how='left')\n",
    "    \n",
    "    # Normalize overtaking index\n",
    "    track_features['overtaking_difficulty'] = 1 - (track_features['overtaking_index'] / track_features['overtaking_index'].max())\n",
    "    \n",
    "    return track_features\n",
    "\n",
    "# Create track features\n",
    "track_features = create_track_features(df_base, circuits)\n",
    "\n",
    "print(\"Track features created:\")\n",
    "print(track_features[['circuitRef', 'is_street_circuit', 'is_high_speed', \n",
    "                      'is_technical', 'overtaking_difficulty']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Weather Features (Simulated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_weather_features(df):\n",
    "    \"\"\"\n",
    "    Simulate weather features based on historical patterns\n",
    "    Note: In production, this would integrate with actual weather APIs\n",
    "    \"\"\"\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    \n",
    "    weather_features = []\n",
    "    \n",
    "    for race_id in df['raceId'].unique():\n",
    "        race_info = df[df['raceId'] == race_id].iloc[0]\n",
    "        \n",
    "        # Simulate based on location and season\n",
    "        month = race_info['date'].month\n",
    "        location = race_info['location']\n",
    "        \n",
    "        # Rain probability based on location and season\n",
    "        if location in ['Silverstone', 'Spa-Francorchamps', 'Suzuka', 'S찾o Paulo']:\n",
    "            rain_prob_base = 0.3\n",
    "        elif location in ['Monaco', 'Singapore', 'Kuala Lumpur']:\n",
    "            rain_prob_base = 0.2\n",
    "        else:\n",
    "            rain_prob_base = 0.1\n",
    "        \n",
    "        # Seasonal adjustment\n",
    "        if month in [6, 7, 8]:  # Summer\n",
    "            rain_prob = rain_prob_base * 0.7\n",
    "        elif month in [3, 4, 5, 9, 10, 11]:  # Spring/Fall\n",
    "            rain_prob = rain_prob_base * 1.2\n",
    "        else:  # Winter\n",
    "            rain_prob = rain_prob_base * 1.5\n",
    "        \n",
    "        # Generate weather conditions\n",
    "        is_wet = np.random.random() < rain_prob\n",
    "        \n",
    "        weather_features.append({\n",
    "            'raceId': race_id,\n",
    "            'rain_probability': min(rain_prob, 0.8),\n",
    "            'is_wet_race': int(is_wet),\n",
    "            'temperature': np.random.normal(22 + (month - 6) * 2, 5),  # Base 22째C with seasonal variation\n",
    "            'track_temp': np.random.normal(30 + (month - 6) * 3, 7),\n",
    "            'humidity': np.random.normal(60 + is_wet * 20, 10),\n",
    "            'wind_speed': np.random.exponential(10),\n",
    "            'weather_changeability': np.random.beta(2, 5)  # How likely weather is to change\n",
    "        })\n",
    "    \n",
    "    weather_df = pd.DataFrame(weather_features)\n",
    "    \n",
    "    # Ensure reasonable ranges\n",
    "    weather_df['temperature'] = weather_df['temperature'].clip(5, 40)\n",
    "    weather_df['track_temp'] = weather_df['track_temp'].clip(10, 60)\n",
    "    weather_df['humidity'] = weather_df['humidity'].clip(20, 95)\n",
    "    weather_df['wind_speed'] = weather_df['wind_speed'].clip(0, 40)\n",
    "    \n",
    "    return weather_df\n",
    "\n",
    "# Generate weather features\n",
    "weather_features = simulate_weather_features(df_base)\n",
    "\n",
    "# Visualize weather distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "axes[0, 0].hist(weather_features['rain_probability'], bins=20, edgecolor='black')\n",
    "axes[0, 0].set_title('Rain Probability Distribution')\n",
    "axes[0, 0].set_xlabel('Probability')\n",
    "\n",
    "axes[0, 1].hist(weather_features['temperature'], bins=20, edgecolor='black')\n",
    "axes[0, 1].set_title('Temperature Distribution')\n",
    "axes[0, 1].set_xlabel('Temperature (째C)')\n",
    "\n",
    "axes[1, 0].scatter(weather_features['temperature'], weather_features['humidity'], \n",
    "                  alpha=0.5, c=weather_features['is_wet_race'], cmap='coolwarm')\n",
    "axes[1, 0].set_xlabel('Temperature (째C)')\n",
    "axes[1, 0].set_ylabel('Humidity (%)')\n",
    "axes[1, 0].set_title('Temperature vs Humidity (color = wet race)')\n",
    "\n",
    "wet_race_pct = weather_features.groupby(pd.cut(weather_features['rain_probability'], \n",
    "                                               bins=5))['is_wet_race'].mean()\n",
    "axes[1, 1].bar(range(len(wet_race_pct)), wet_race_pct.values)\n",
    "axes[1, 1].set_xlabel('Rain Probability Bins')\n",
    "axes[1, 1].set_ylabel('Actual Wet Race %')\n",
    "axes[1, 1].set_title('Rain Probability vs Actual Wet Races')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nWeather features generated for {len(weather_features)} races\")\n",
    "print(f\"Wet race percentage: {weather_features['is_wet_race'].mean():.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Momentum and Form Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_momentum_features(df, windows=[3, 5, 10]):\n",
    "    \"\"\"\n",
    "    Create momentum and form indicators\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df = df.sort_values(['driverId', 'date'])\n",
    "    \n",
    "    # Driver momentum features\n",
    "    for w in windows:\n",
    "        # Position trend\n",
    "        df[f'position_trend_{w}'] = df.groupby('driverId')['positionOrder'].transform(\n",
    "            lambda x: x.shift(1).rolling(window=w, min_periods=1).apply(\n",
    "                lambda y: stats.linregress(range(len(y)), y)[0] if len(y) > 1 else 0\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Points momentum\n",
    "        df[f'points_momentum_{w}'] = df.groupby('driverId')['points'].transform(\n",
    "            lambda x: x.shift(1).rolling(window=w, min_periods=1).mean()\n",
    "        )\n",
    "        \n",
    "        # Consistency score (inverse of std deviation)\n",
    "        df[f'consistency_{w}'] = df.groupby('driverId')['positionOrder'].transform(\n",
    "            lambda x: 1 / (1 + x.shift(1).rolling(window=w, min_periods=1).std())\n",
    "        )\n",
    "        \n",
    "        # Beat teammate rate\n",
    "        df['beat_teammate'] = df.groupby(['raceId', 'constructorId'])['positionOrder'].rank() == 1\n",
    "        df[f'teammate_dominance_{w}'] = df.groupby('driverId')['beat_teammate'].transform(\n",
    "            lambda x: x.shift(1).rolling(window=w, min_periods=1).mean()\n",
    "        )\n",
    "    \n",
    "    # Constructor momentum\n",
    "    constructor_points = df.groupby(['raceId', 'constructorId'])['points'].sum().reset_index()\n",
    "    constructor_points = constructor_points.sort_values(['constructorId', 'raceId'])\n",
    "    \n",
    "    for w in windows:\n",
    "        constructor_points[f'constructor_momentum_{w}'] = constructor_points.groupby('constructorId')['points'].transform(\n",
    "            lambda x: x.rolling(window=w, min_periods=1).mean()\n",
    "        )\n",
    "    \n",
    "    # Merge back\n",
    "    df = df.merge(constructor_points.drop('points', axis=1), on=['raceId', 'constructorId'], how='left')\n",
    "    \n",
    "    # Championship pressure (position in standings)\n",
    "    if not driver_standings.empty:\n",
    "        standings_features = driver_standings.groupby(['raceId', 'driverId']).agg({\n",
    "            'position': 'first',\n",
    "            'points': 'first'\n",
    "        }).reset_index()\n",
    "        standings_features.columns = ['raceId', 'driverId', 'championship_position', 'championship_points']\n",
    "        \n",
    "        df = df.merge(standings_features, on=['raceId', 'driverId'], how='left')\n",
    "        \n",
    "        # Points gap to leader\n",
    "        max_points = df.groupby('raceId')['championship_points'].transform('max')\n",
    "        df['points_gap_to_leader'] = max_points - df['championship_points']\n",
    "        df['championship_pressure'] = 1 / (1 + df['championship_position'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Create momentum features\n",
    "df_momentum = create_momentum_features(df_base)\n",
    "\n",
    "# Visualize momentum trends\n",
    "recent_data = df_momentum[df_momentum['year'] >= 2020]\n",
    "top_drivers = recent_data.groupby('driverId')['points'].sum().nlargest(10).index\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "for driver_id in top_drivers[:5]:\n",
    "    driver_data = recent_data[recent_data['driverId'] == driver_id].sort_values('date')\n",
    "    driver_name = driver_data['surname'].iloc[0]\n",
    "    \n",
    "    ax.plot(driver_data['date'], \n",
    "           driver_data['points_momentum_5'].rolling(3).mean(), \n",
    "           label=driver_name, linewidth=2)\n",
    "\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Points Momentum (5-race average)')\n",
    "ax.set_title('Driver Momentum Trends (Top 5 Drivers)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nMomentum features created:\")\n",
    "momentum_cols = [col for col in df_momentum.columns if 'momentum' in col or 'trend' in col]\n",
    "print(f\"Total momentum features: {len(momentum_cols)}\")\n",
    "print(f\"Sample features: {momentum_cols[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Strategy Pattern Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_strategy_features(df, pit_stops, lap_times):\n",
    "    \"\"\"\n",
    "    Create features related to team strategy patterns\n",
    "    \"\"\"\n",
    "    strategy_features = []\n",
    "    \n",
    "    # Pit stop analysis\n",
    "    if not pit_stops.empty:\n",
    "        # Average pit stops per race\n",
    "        pit_stop_stats = pit_stops.groupby(['raceId', 'driverId']).agg({\n",
    "            'stop': 'count',\n",
    "            'milliseconds': ['mean', 'std'],\n",
    "            'lap': ['min', 'max']\n",
    "        }).reset_index()\n",
    "        \n",
    "        pit_stop_stats.columns = ['raceId', 'driverId', 'n_pit_stops', \n",
    "                                  'avg_pit_time', 'pit_time_variance',\n",
    "                                  'first_stop_lap', 'last_stop_lap']\n",
    "        \n",
    "        # Calculate pit stop efficiency by constructor\n",
    "        constructor_pit_efficiency = pit_stops.merge(\n",
    "            df[['raceId', 'driverId', 'constructorId']].drop_duplicates(),\n",
    "            on=['raceId', 'driverId']\n",
    "        ).groupby('constructorId')['milliseconds'].agg(['mean', 'std']).reset_index()\n",
    "        \n",
    "        constructor_pit_efficiency.columns = ['constructorId', \n",
    "                                             'constructor_avg_pit_time', \n",
    "                                             'constructor_pit_consistency']\n",
    "    else:\n",
    "        pit_stop_stats = pd.DataFrame()\n",
    "        constructor_pit_efficiency = pd.DataFrame()\n",
    "    \n",
    "    # Lap time consistency\n",
    "    if not lap_times.empty:\n",
    "        # Sample lap times (full dataset is too large)\n",
    "        sample_races = df['raceId'].unique()[-20:]  # Last 20 races\n",
    "        lap_time_sample = lap_times[lap_times['raceId'].isin(sample_races)]\n",
    "        \n",
    "        lap_consistency = lap_time_sample.groupby(['raceId', 'driverId']).agg({\n",
    "            'milliseconds': ['mean', 'std', 'min']\n",
    "        }).reset_index()\n",
    "        \n",
    "        lap_consistency.columns = ['raceId', 'driverId', \n",
    "                                  'avg_lap_time', 'lap_time_std', 'fastest_lap']\n",
    "        \n",
    "        lap_consistency['lap_consistency_score'] = 1 / (1 + lap_consistency['lap_time_std'] / lap_consistency['avg_lap_time'])\n",
    "    else:\n",
    "        lap_consistency = pd.DataFrame()\n",
    "    \n",
    "    # Tire strategy patterns (inferred from pit stop timing)\n",
    "    if not pit_stop_stats.empty:\n",
    "        # Classify strategies\n",
    "        def classify_strategy(row):\n",
    "            if pd.isna(row['n_pit_stops']):\n",
    "                return 'unknown'\n",
    "            elif row['n_pit_stops'] == 1:\n",
    "                return 'one_stop'\n",
    "            elif row['n_pit_stops'] == 2:\n",
    "                return 'two_stop'\n",
    "            else:\n",
    "                return 'multi_stop'\n",
    "        \n",
    "        pit_stop_stats['strategy_type'] = pit_stop_stats.apply(classify_strategy, axis=1)\n",
    "    \n",
    "    # Merge all strategy features\n",
    "    df_strategy = df.copy()\n",
    "    \n",
    "    if not pit_stop_stats.empty:\n",
    "        df_strategy = df_strategy.merge(pit_stop_stats, on=['raceId', 'driverId'], how='left')\n",
    "    \n",
    "    if not constructor_pit_efficiency.empty:\n",
    "        df_strategy = df_strategy.merge(constructor_pit_efficiency, on='constructorId', how='left')\n",
    "    \n",
    "    if not lap_consistency.empty:\n",
    "        df_strategy = df_strategy.merge(lap_consistency, on=['raceId', 'driverId'], how='left')\n",
    "    \n",
    "    # Calculate constructor strategy preferences\n",
    "    if 'strategy_type' in df_strategy.columns:\n",
    "        strategy_prefs = df_strategy.groupby(['constructorId', 'strategy_type']).size().unstack(fill_value=0)\n",
    "        strategy_prefs = strategy_prefs.div(strategy_prefs.sum(axis=1), axis=0)\n",
    "        \n",
    "        # Visualize strategy preferences\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        \n",
    "        top_constructors = df_strategy.groupby('constructorId').size().nlargest(10).index\n",
    "        strategy_prefs_top = strategy_prefs.loc[top_constructors]\n",
    "        \n",
    "        strategy_prefs_top.plot(kind='bar', stacked=True, ax=ax)\n",
    "        ax.set_xlabel('Constructor ID')\n",
    "        ax.set_ylabel('Strategy Preference %')\n",
    "        ax.set_title('Pit Stop Strategy Preferences by Constructor')\n",
    "        ax.legend(title='Strategy Type')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return df_strategy\n",
    "\n",
    "# Create strategy features\n",
    "df_strategy = create_strategy_features(df_momentum, pit_stops, lap_times)\n",
    "\n",
    "print(\"\\nStrategy features created\")\n",
    "strategy_cols = ['n_pit_stops', 'avg_pit_time', 'constructor_avg_pit_time', \n",
    "                'lap_consistency_score', 'strategy_type']\n",
    "available_cols = [col for col in strategy_cols if col in df_strategy.columns]\n",
    "print(f\"Available strategy features: {available_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Advanced Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_advanced_metrics(df):\n",
    "    \"\"\"\n",
    "    Create advanced performance metrics\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Relative performance to teammate\n",
    "    teammate_comparison = df.groupby(['raceId', 'constructorId']).apply(\n",
    "        lambda x: x.assign(\n",
    "            teammate_position_diff=x['positionOrder'] - x['positionOrder'].mean(),\n",
    "            teammate_points_ratio=x['points'] / (x['points'].sum() + 0.1)\n",
    "        )\n",
    "    ).reset_index(drop=True)\n",
    "    \n",
    "    df['teammate_position_diff'] = teammate_comparison['teammate_position_diff']\n",
    "    df['teammate_points_ratio'] = teammate_comparison['teammate_points_ratio']\n",
    "    \n",
    "    # Era-adjusted performance (account for different eras having different competitiveness)\n",
    "    era_adjustment = df.groupby('year').agg({\n",
    "        'points': ['mean', 'std'],\n",
    "        'positionOrder': ['mean', 'std']\n",
    "    })\n",
    "    \n",
    "    era_adjustment.columns = ['era_avg_points', 'era_std_points', \n",
    "                              'era_avg_position', 'era_std_position']\n",
    "    \n",
    "    df = df.merge(era_adjustment, left_on='year', right_index=True, how='left')\n",
    "    \n",
    "    # Standardize performance by era\n",
    "    df['era_adjusted_points'] = (df['points'] - df['era_avg_points']) / (df['era_std_points'] + 0.1)\n",
    "    df['era_adjusted_position'] = (df['era_avg_position'] - df['positionOrder']) / (df['era_std_position'] + 0.1)\n",
    "    \n",
    "    # Performance in different race phases\n",
    "    df['start_performance'] = np.clip((df['grid'] - df['position'].fillna(df['positionOrder'])) / df['grid'], -1, 1)\n",
    "    \n",
    "    # Clutch factor (performance in high-pressure situations)\n",
    "    # Define high pressure as: late season races, close championship battles\n",
    "    df['is_late_season'] = df['round'] >= df.groupby('year')['round'].transform('max') * 0.75\n",
    "    df['clutch_points'] = df['points'] * df['is_late_season']\n",
    "    \n",
    "    # Calculate driver clutch factor\n",
    "    clutch_stats = df.groupby('driverId').agg({\n",
    "        'clutch_points': 'mean',\n",
    "        'points': 'mean'\n",
    "    })\n",
    "    clutch_stats['clutch_factor'] = clutch_stats['clutch_points'] / (clutch_stats['points'] + 0.1)\n",
    "    \n",
    "    df = df.merge(clutch_stats[['clutch_factor']], left_on='driverId', right_index=True, how='left')\n",
    "    \n",
    "    # Head-to-head records\n",
    "    h2h_records = []\n",
    "    top_drivers = df.groupby('driverId')['points'].sum().nlargest(20).index\n",
    "    \n",
    "    for d1 in top_drivers[:10]:  # Limit for performance\n",
    "        for d2 in top_drivers[:10]:\n",
    "            if d1 < d2:  # Avoid duplicates\n",
    "                races_together = df[\n",
    "                    (df['driverId'].isin([d1, d2])) & \n",
    "                    (df['raceId'].isin(\n",
    "                        df[df['driverId'] == d1]['raceId'].intersection(\n",
    "                            df[df['driverId'] == d2]['raceId']\n",
    "                        )\n",
    "                    ))\n",
    "                ]\n",
    "                \n",
    "                if len(races_together) > 10:  # Minimum races together\n",
    "                    d1_wins = 0\n",
    "                    d2_wins = 0\n",
    "                    \n",
    "                    for race in races_together['raceId'].unique():\n",
    "                        race_data = races_together[races_together['raceId'] == race]\n",
    "                        d1_pos = race_data[race_data['driverId'] == d1]['positionOrder'].values\n",
    "                        d2_pos = race_data[race_data['driverId'] == d2]['positionOrder'].values\n",
    "                        \n",
    "                        if len(d1_pos) > 0 and len(d2_pos) > 0:\n",
    "                            if d1_pos[0] < d2_pos[0]:\n",
    "                                d1_wins += 1\n",
    "                            else:\n",
    "                                d2_wins += 1\n",
    "                    \n",
    "                    h2h_records.append({\n",
    "                        'driver1': d1,\n",
    "                        'driver2': d2,\n",
    "                        'driver1_wins': d1_wins,\n",
    "                        'driver2_wins': d2_wins,\n",
    "                        'total_races': d1_wins + d2_wins\n",
    "                    })\n",
    "    \n",
    "    h2h_df = pd.DataFrame(h2h_records)\n",
    "    \n",
    "    # Visualize advanced metrics\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # Era-adjusted performance over time\n",
    "    era_performance = df.groupby('year')['era_adjusted_points'].mean()\n",
    "    axes[0, 0].plot(era_performance.index, era_performance.values)\n",
    "    axes[0, 0].set_xlabel('Year')\n",
    "    axes[0, 0].set_ylabel('Era-Adjusted Points')\n",
    "    axes[0, 0].set_title('Average Era-Adjusted Performance Over Time')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Clutch factor distribution\n",
    "    axes[0, 1].hist(clutch_stats['clutch_factor'].dropna(), bins=20, edgecolor='black')\n",
    "    axes[0, 1].set_xlabel('Clutch Factor')\n",
    "    axes[0, 1].set_ylabel('Number of Drivers')\n",
    "    axes[0, 1].set_title('Distribution of Driver Clutch Factors')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Teammate performance comparison\n",
    "    recent_teammate_diff = df[df['year'] >= 2020].groupby('driverId')['teammate_position_diff'].mean()\n",
    "    top_teammates = recent_teammate_diff.nsmallest(10)\n",
    "    \n",
    "    axes[1, 0].barh(range(len(top_teammates)), top_teammates.values)\n",
    "    axes[1, 0].set_yticks(range(len(top_teammates)))\n",
    "    axes[1, 0].set_yticklabels([drivers[drivers['driverId'] == d]['surname'].iloc[0] \n",
    "                                for d in top_teammates.index])\n",
    "    axes[1, 0].set_xlabel('Average Position Difference vs Teammate')\n",
    "    axes[1, 0].set_title('Top 10 Drivers vs Teammates (2020+)')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Head-to-head matrix\n",
    "    if not h2h_df.empty:\n",
    "        # Create matrix for visualization\n",
    "        h2h_pivot = h2h_df.pivot_table(\n",
    "            values='driver1_wins', \n",
    "            index='driver1', \n",
    "            columns='driver2',\n",
    "            aggfunc='sum'\n",
    "        )\n",
    "        \n",
    "        # Get driver names\n",
    "        driver_names = {d: drivers[drivers['driverId'] == d]['surname'].iloc[0] \n",
    "                       for d in h2h_pivot.index if d in drivers['driverId'].values}\n",
    "        \n",
    "        h2h_pivot.index = [driver_names.get(d, f'Driver{d}') for d in h2h_pivot.index]\n",
    "        h2h_pivot.columns = [driver_names.get(d, f'Driver{d}') for d in h2h_pivot.columns]\n",
    "        \n",
    "        sns.heatmap(h2h_pivot.fillna(0), annot=True, fmt='.0f', cmap='RdYlGn', \n",
    "                   ax=axes[1, 1], cbar_kws={'label': 'Wins'})\n",
    "        axes[1, 1].set_title('Head-to-Head Records (Top Drivers)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return df, h2h_df\n",
    "\n",
    "# Create advanced metrics\n",
    "df_advanced, h2h_records = create_advanced_metrics(df_strategy)\n",
    "\n",
    "print(\"\\nAdvanced metrics created:\")\n",
    "advanced_cols = ['era_adjusted_points', 'era_adjusted_position', 'teammate_position_diff', \n",
    "                'clutch_factor', 'start_performance']\n",
    "print(f\"New advanced features: {[col for col in advanced_cols if col in df_advanced.columns]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Store Assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1FeatureStore:\n",
    "    \"\"\"\n",
    "    Centralized feature store for F1 predictions\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.base_features = None\n",
    "        self.track_features = None\n",
    "        self.weather_features = None\n",
    "        self.feature_metadata = {}\n",
    "        \n",
    "    def build_feature_store(self, df, track_features, weather_features):\n",
    "        \"\"\"\n",
    "        Assemble all features into a unified store\n",
    "        \"\"\"\n",
    "        # Start with base dataframe\n",
    "        self.base_features = df.copy()\n",
    "        \n",
    "        # Add track features\n",
    "        self.base_features = self.base_features.merge(\n",
    "            track_features, on='circuitId', how='left', suffixes=('', '_track')\n",
    "        )\n",
    "        \n",
    "        # Add weather features\n",
    "        self.base_features = self.base_features.merge(\n",
    "            weather_features, on='raceId', how='left'\n",
    "        )\n",
    "        \n",
    "        # Store feature metadata\n",
    "        self._create_feature_metadata()\n",
    "        \n",
    "        return self.base_features\n",
    "    \n",
    "    def _create_feature_metadata(self):\n",
    "        \"\"\"\n",
    "        Create metadata about features for documentation\n",
    "        \"\"\"\n",
    "        feature_groups = {\n",
    "            'basic': ['grid', 'positionOrder', 'points', 'laps', 'statusId'],\n",
    "            'driver': ['driver_age', 'driverId', 'constructorId'],\n",
    "            'track': ['is_street_circuit', 'is_high_speed', 'is_technical', \n",
    "                     'overtaking_difficulty', 'dnf_rate'],\n",
    "            'weather': ['rain_probability', 'is_wet_race', 'temperature', \n",
    "                       'humidity', 'wind_speed'],\n",
    "            'momentum': [col for col in self.base_features.columns if 'momentum' in col or 'trend' in col],\n",
    "            'strategy': ['n_pit_stops', 'avg_pit_time', 'lap_consistency_score'],\n",
    "            'advanced': ['era_adjusted_points', 'teammate_position_diff', \n",
    "                        'clutch_factor', 'start_performance']\n",
    "        }\n",
    "        \n",
    "        for group, features in feature_groups.items():\n",
    "            available_features = [f for f in features if f in self.base_features.columns]\n",
    "            self.feature_metadata[group] = {\n",
    "                'features': available_features,\n",
    "                'count': len(available_features),\n",
    "                'missing': [f for f in features if f not in self.base_features.columns]\n",
    "            }\n",
    "    \n",
    "    def get_feature_set(self, feature_groups=['basic', 'driver', 'momentum']):\n",
    "        \"\"\"\n",
    "        Get specific feature sets for modeling\n",
    "        \"\"\"\n",
    "        features = []\n",
    "        for group in feature_groups:\n",
    "            if group in self.feature_metadata:\n",
    "                features.extend(self.feature_metadata[group]['features'])\n",
    "        \n",
    "        return list(set(features))  # Remove duplicates\n",
    "    \n",
    "    def get_race_features(self, race_id):\n",
    "        \"\"\"\n",
    "        Get all features for a specific race\n",
    "        \"\"\"\n",
    "        return self.base_features[self.base_features['raceId'] == race_id]\n",
    "    \n",
    "    def get_driver_features(self, driver_id, last_n_races=None):\n",
    "        \"\"\"\n",
    "        Get features for a specific driver\n",
    "        \"\"\"\n",
    "        driver_data = self.base_features[self.base_features['driverId'] == driver_id]\n",
    "        \n",
    "        if last_n_races:\n",
    "            driver_data = driver_data.sort_values('date').tail(last_n_races)\n",
    "        \n",
    "        return driver_data\n",
    "    \n",
    "    def save_feature_store(self, path='f1_feature_store.parquet'):\n",
    "        \"\"\"\n",
    "        Save feature store to disk\n",
    "        \"\"\"\n",
    "        self.base_features.to_parquet(path, index=False)\n",
    "        \n",
    "        # Save metadata\n",
    "        with open(path.replace('.parquet', '_metadata.json'), 'w') as f:\n",
    "            json.dump(self.feature_metadata, f, indent=2)\n",
    "        \n",
    "        print(f\"Feature store saved to {path}\")\n",
    "    \n",
    "    def load_feature_store(self, path='f1_feature_store.parquet'):\n",
    "        \"\"\"\n",
    "        Load feature store from disk\n",
    "        \"\"\"\n",
    "        self.base_features = pd.read_parquet(path)\n",
    "        \n",
    "        # Load metadata\n",
    "        with open(path.replace('.parquet', '_metadata.json'), 'r') as f:\n",
    "            self.feature_metadata = json.load(f)\n",
    "        \n",
    "        print(f\"Feature store loaded from {path}\")\n",
    "\n",
    "# Create and populate feature store\n",
    "feature_store = F1FeatureStore()\n",
    "all_features = feature_store.build_feature_store(df_advanced, track_features, weather_features)\n",
    "\n",
    "print(\"\\nFeature Store Summary:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total records: {len(all_features):,}\")\n",
    "print(f\"Total features: {len(all_features.columns)}\")\n",
    "print(f\"Date range: {all_features['date'].min()} to {all_features['date'].max()}\")\n",
    "print(f\"\\nFeature groups:\")\n",
    "for group, metadata in feature_store.feature_metadata.items():\n",
    "    print(f\"  {group}: {metadata['count']} features\")\n",
    "\n",
    "# Save feature store\n",
    "feature_store.save_feature_store('f1_feature_store.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Feature Quality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_feature_quality(feature_store):\n",
    "    \"\"\"\n",
    "    Analyze feature quality and usefulness\n",
    "    \"\"\"\n",
    "    df = feature_store.base_features\n",
    "    \n",
    "    # Get numeric features only\n",
    "    numeric_features = df.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    # Calculate feature statistics\n",
    "    feature_stats = []\n",
    "    \n",
    "    for feature in numeric_features:\n",
    "        if feature in ['raceId', 'driverId', 'constructorId', 'circuitId']:  # Skip IDs\n",
    "            continue\n",
    "            \n",
    "        stats = {\n",
    "            'feature': feature,\n",
    "            'missing_pct': df[feature].isna().mean() * 100,\n",
    "            'unique_values': df[feature].nunique(),\n",
    "            'std_dev': df[feature].std(),\n",
    "            'skewness': df[feature].skew(),\n",
    "            'kurtosis': df[feature].kurtosis()\n",
    "        }\n",
    "        \n",
    "        # Correlation with target (position)\n",
    "        if 'positionOrder' in df.columns:\n",
    "            stats['correlation_with_position'] = df[feature].corr(df['positionOrder'])\n",
    "        \n",
    "        feature_stats.append(stats)\n",
    "    \n",
    "    feature_quality_df = pd.DataFrame(feature_stats)\n",
    "    \n",
    "    # Identify potential issues\n",
    "    print(\"\\nFeature Quality Analysis:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # High missing data\n",
    "    high_missing = feature_quality_df[feature_quality_df['missing_pct'] > 20]\n",
    "    if not high_missing.empty:\n",
    "        print(\"\\nFeatures with >20% missing data:\")\n",
    "        print(high_missing[['feature', 'missing_pct']].round(1))\n",
    "    \n",
    "    # Low variance features\n",
    "    low_variance = feature_quality_df[feature_quality_df['std_dev'] < 0.01]\n",
    "    if not low_variance.empty:\n",
    "        print(\"\\nLow variance features (might not be useful):\")\n",
    "        print(low_variance[['feature', 'std_dev']])\n",
    "    \n",
    "    # Highly correlated with target\n",
    "    if 'correlation_with_position' in feature_quality_df.columns:\n",
    "        high_corr = feature_quality_df.nlargest(10, 'correlation_with_position')\n",
    "        print(\"\\nTop 10 features correlated with position:\")\n",
    "        print(high_corr[['feature', 'correlation_with_position']].round(3))\n",
    "    \n",
    "    # Visualize feature distributions\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # Missing data\n",
    "    missing_data = feature_quality_df.nlargest(15, 'missing_pct')\n",
    "    axes[0, 0].barh(missing_data['feature'], missing_data['missing_pct'])\n",
    "    axes[0, 0].set_xlabel('Missing %')\n",
    "    axes[0, 0].set_title('Features with Most Missing Data')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Feature importance proxy (absolute correlation)\n",
    "    if 'correlation_with_position' in feature_quality_df.columns:\n",
    "        feature_quality_df['abs_correlation'] = feature_quality_df['correlation_with_position'].abs()\n",
    "        top_corr = feature_quality_df.nlargest(15, 'abs_correlation')\n",
    "        axes[0, 1].barh(top_corr['feature'], top_corr['abs_correlation'])\n",
    "        axes[0, 1].set_xlabel('Absolute Correlation with Position')\n",
    "        axes[0, 1].set_title('Most Predictive Features')\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Skewness distribution\n",
    "    axes[1, 0].hist(feature_quality_df['skewness'].dropna(), bins=30, edgecolor='black')\n",
    "    axes[1, 0].set_xlabel('Skewness')\n",
    "    axes[1, 0].set_ylabel('Number of Features')\n",
    "    axes[1, 0].set_title('Feature Skewness Distribution')\n",
    "    axes[1, 0].axvline(x=0, color='red', linestyle='--', label='No skew')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Feature count by group\n",
    "    group_counts = pd.Series({group: metadata['count'] \n",
    "                             for group, metadata in feature_store.feature_metadata.items()})\n",
    "    axes[1, 1].pie(group_counts.values, labels=group_counts.index, autopct='%1.1f%%')\n",
    "    axes[1, 1].set_title('Feature Distribution by Group')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return feature_quality_df\n",
    "\n",
    "# Analyze feature quality\n",
    "feature_quality = analyze_feature_quality(feature_store)\n",
    "\n",
    "# Get recommended feature set\n",
    "recommended_features = feature_store.get_feature_set(\n",
    "    ['basic', 'driver', 'track', 'weather', 'momentum', 'advanced']\n",
    ")\n",
    "print(f\"\\nRecommended feature set: {len(recommended_features)} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The F1 Feature Store provides:\n",
    "\n",
    "1. **Track Characteristics**: Circuit type, overtaking difficulty, historical performance\n",
    "2. **Weather Features**: Simulated weather conditions affecting race outcomes\n",
    "3. **Momentum Indicators**: Recent form, consistency, championship pressure\n",
    "4. **Strategy Patterns**: Pit stop timing, tire strategies, team preferences\n",
    "5. **Advanced Metrics**: Era-adjusted performance, clutch factor, head-to-head records\n",
    "\n",
    "### Key Insights:\n",
    "- Weather significantly impacts race strategies and outcomes\n",
    "- Momentum features capture driver form better than static averages\n",
    "- Track characteristics strongly influence overtaking opportunities\n",
    "- Team strategy patterns are predictable and vary by constructor\n",
    "\n",
    "The feature store is saved as a Parquet file for efficient storage and quick loading in production models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}